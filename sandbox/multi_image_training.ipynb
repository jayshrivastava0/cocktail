{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVC/dtFIfefc7u/sN+dlnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realtechsupport/cocktail/blob/main/sandbox/multi_image_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. create functions to preprocess the input image:\n",
        "2. the function should have normalization, resize, creating patches\n",
        "3. all the images should be converted into lists of patches\n",
        "4. these lists are sampled and useful lists are created\n",
        "5. then combine all the sampled into to bigger list,\n",
        "4. then a numpy array\n"
      ],
      "metadata": {
        "id": "vHxXD3_YSbNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXSuS5jdYI_3",
        "outputId": "cc55dae9-04af-4d9d-87e8-053c86da6ed5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-hCN74DTG3P",
        "outputId": "72f90789-6fd9-4471-ac48-7f1feadea705"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "def preprocessing(filelocation):\n",
        "    # Load the GeoTIFF file\n",
        "    with rasterio.open(filelocation) as src:\n",
        "        # Read the TIFF data\n",
        "        tiff_data = src.read()\n",
        "\n",
        "        # Get the shape of the TIFF data\n",
        "        num_bands, height, width = tiff_data.shape\n",
        "\n",
        "        print(\"Original image dimensions:\", num_bands, height, width)\n",
        "\n",
        "        print(np.min(tiff_data), np.max(tiff_data))\n",
        "\n",
        "\n",
        "        normalized_image = np.zeros_like(tiff_data, dtype='float32')\n",
        "        for band in range(tiff_data.shape[1]):\n",
        "            band_min = np.min(tiff_data[:, band])\n",
        "            band_max = np.max(tiff_data[:, band])\n",
        "            normalized_image[:, band] = (tiff_data[:, band] - band_min) / (band_max - band_min)\n",
        "\n",
        "        # Calculate the new width and height that are multiples of the patch size\n",
        "        patch_size = 256  # Replace with your desired patch size\n",
        "        new_width = int(np.floor(width / patch_size)) * patch_size\n",
        "        new_height = int(np.floor(height / patch_size)) * patch_size\n",
        "\n",
        "        print(\"cropped dimensions:\", new_height, new_width)\n",
        "\n",
        "        input_image = np.moveaxis(normalized_image, 0, -1)\n",
        "\n",
        "        # Crop the input_image to the new dimensions\n",
        "        cropped_array = input_image[:new_height, :new_width, :]\n",
        "\n",
        "    print(\"Cropped array shape:\", cropped_array.shape)\n",
        "    print(np.min(cropped_array), np.max(cropped_array))\n",
        "\n",
        "    patches = []\n",
        "    for i in range(0, cropped_array.shape[0], patch_size):\n",
        "        for j in range(0, cropped_array.shape[1], patch_size):\n",
        "            patch = cropped_array[i:i+patch_size, j:j+patch_size]\n",
        "            patches.append(patch)\n",
        "    print(\"patches are created\")\n",
        "    return patches"
      ],
      "metadata": {
        "id": "prlfXjI2TOJ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(training_images, mask_array):\n",
        "    useful_images = []\n",
        "    useful_masks = []\n",
        "    useless = 0\n",
        "    indexes = []\n",
        "    for img in range(len(training_images)):\n",
        "        img_name=training_images[img]\n",
        "        mask_name = mask_array[img]\n",
        "\n",
        "        val, counts = np.unique(mask_name, return_counts=True)\n",
        "\n",
        "        if (1 - (counts[0]/counts.sum())) > 0.05:\n",
        "          useful_images.append(img_name)\n",
        "          useful_masks.append(mask_name)\n",
        "          indexes.append(img)\n",
        "          print(\"I am useful\")\n",
        "\n",
        "        else:\n",
        "          #print(\"I am useless\")\n",
        "          useless +=1\n",
        "\n",
        "\n",
        "    print(\"Total useful images are: \", len(training_images)-useless)\n",
        "    print(indexes)\n",
        "    print(\"Total useless images are: \", useless)\n",
        "\n",
        "    return useful_images"
      ],
      "metadata": {
        "id": "Vfs8hNJSTxoN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_lists(lists_of_arrays):\n",
        "    \"\"\"\n",
        "    Combine lists of arrays into a single list.\n",
        "\n",
        "    Args:\n",
        "    lists_of_arrays (list): A list of lists, where each inner list contains arrays.\n",
        "\n",
        "    Returns:\n",
        "    combined_list (list): A single list containing all arrays from the input lists.\n",
        "    \"\"\"\n",
        "    combined_list = []\n",
        "\n",
        "    for arr_list in lists_of_arrays:\n",
        "        combined_list.extend(arr_list)\n",
        "\n",
        "    return combined_list\n",
        "\n",
        "# # Example usage:\n",
        "# list1 = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
        "# list2 = [np.array([7, 8, 9]), np.array([10, 11, 12])]\n",
        "\n",
        "# lists_of_arrays = [list1, list2]\n",
        "# combined_list = combine_lists(lists_of_arrays)\n",
        "\n",
        "# print(combined_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "pWmSDKrmVRU6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2o4NVD8eXqgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create mask_array\n",
        "\n",
        "def preprocess_mask(filelocation):\n",
        "\n",
        "\n",
        "    with rasterio.open(filelocation) as src:\n",
        "        # Read the TIFF data\n",
        "        output_mask = src.read()\n",
        "        num_bands, height, width = src.shape\n",
        "\n",
        "        # Calculate the new width and height that are multiples of the patch size\n",
        "        patch_size = 256  # Replace with your desired patch size\n",
        "        new_width = int(np.floor(width / patch_size)) * patch_size\n",
        "        new_height = int(np.floor(height / patch_size)) * patch_size\n",
        "\n",
        "        print(\"cropped dimensions:\", new_height, new_width)\n",
        "\n",
        "        output_mask = np.moveaxis(output_mask, 0, -1)\n",
        "\n",
        "        # Crop the input_image to the new dimensions\n",
        "        cropped_mask = output_mask[:new_height, :new_width, :]\n",
        "\n",
        "        print(\"Cropped array shape:\", cropped_mask.shape)\n",
        "\n",
        "        new_mask = np.squeeze(cropped_mask)\n",
        "\n",
        "    masks = []\n",
        "    for i in range(0, new_mask.shape[0], patch_size):\n",
        "        for j in range(0, new_mask.shape[1], patch_size):\n",
        "            patch = new_mask[i:i+patch_size, j:j+patch_size]\n",
        "            masks.append(patch)\n",
        "    return masks\n"
      ],
      "metadata": {
        "id": "Jv9zXMSgWYYC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine masks\n",
        "#apply one hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "def onehotencoding(labels, num_classes=23):\n",
        "    return to_categorical(labels, num_classes)\n",
        "mask_array = np.array(masks)"
      ],
      "metadata": {
        "id": "fYrAMJ6IXSrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. load each image, preprocess and create patches\n",
        "2. load the mask and create mask-array\n",
        "3. sample each image-patch with mask\n",
        "4. get the useful patches\n",
        "5. combine useful patches and convert into one numpy array\n",
        "6. combine masks and convert them into one numpy array\n"
      ],
      "metadata": {
        "id": "MknQ4WqDXtf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patch_1 = preprocessing('/content/gdrive/MyDrive/exp/other images/public-archivedwl-5/area2_0123_2023_8bands.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ifT2e3iYDY-",
        "outputId": "a799eb52-487c-4688-88e6-99a02278e4d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4085 4686\n",
            "1.0 10888.0\n",
            "cropped dimensions: 3840 4608\n",
            "Cropped array shape: (3840, 4608, 8)\n",
            "0.0 1.0\n",
            "patches are created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_1 = preprocessing('/content/gdrive/MyDrive/exp/other images/public-archivedwl-5/area2_0516_2023_8bands.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xiSyuWgpFTo",
        "outputId": "72d5bd87-6287-4872-f759-0a8030db8a5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4093 4691\n",
            "0.0 9013.286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8ffb9f218957>:20: RuntimeWarning: invalid value encountered in divide\n",
            "  normalized_image[:, band] = (tiff_data[:, band] - band_min) / (band_max - band_min)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped dimensions: 3840 4608\n",
            "Cropped array shape: (3840, 4608, 8)\n",
            "nan nan\n",
            "patches are created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_3 = preprocessing('/content/gdrive/MyDrive/exp/other images/public-archivedwl-5/area2_0516_2023_8bands_composite.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j280aYucY0Oy",
        "outputId": "a8c311cf-e994-4270-9360-354370ff199f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4013 4591\n",
            "0 9977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8ffb9f218957>:20: RuntimeWarning: invalid value encountered in divide\n",
            "  normalized_image[:, band] = (tiff_data[:, band] - band_min) / (band_max - band_min)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped dimensions: 3840 4352\n",
            "Cropped array shape: (3840, 4352, 8)\n",
            "0.0 1.0\n",
            "patches are created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_4 = preprocessing('/content/gdrive/MyDrive/exp/other images/public-archivedwl-5/area2_0530_2022_8bands.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "429aEVN7ZSuF",
        "outputId": "32cd2548-b1b0-4cb4-9e9c-50a8b785c4ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4019 4618\n",
            "1.0 10610.0\n",
            "cropped dimensions: 3840 4608\n",
            "Cropped array shape: (3840, 4608, 8)\n",
            "0.0 1.0\n",
            "patches are created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_5 = preprocessing('/content/gdrive/MyDrive/exp/other images/public-archivedwl-5/area2_0617_2023_8bands.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLyrxPqsZcLC",
        "outputId": "801845ec-6fa3-4e14-ce0e-31818057bac4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4093 4691\n",
            "0.0 14912.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8ffb9f218957>:20: RuntimeWarning: invalid value encountered in divide\n",
            "  normalized_image[:, band] = (tiff_data[:, band] - band_min) / (band_max - band_min)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped dimensions: 3840 4608\n",
            "Cropped array shape: (3840, 4608, 8)\n",
            "nan nan\n",
            "patches are created\n"
          ]
        }
      ]
    }
  ]
}