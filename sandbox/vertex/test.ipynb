{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a12841-c347-4d6d-88fe-17f76c69c91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /opt/conda/lib/python3.10/site-packages (1.3.9)\n",
      "Requirement already satisfied: affine in /opt/conda/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2023.11.17)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.23.5)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from rasterio) (68.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (0.14.3)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[39 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/_parser.py\", line 126, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/_parser.py\", line 147, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-83s1i0sa/tensorflow-gpu_d157cc7ce8d94d39bfca2138784f289b/setup.py\", line 40, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 102, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 73, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 655, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 390, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._normalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 405, in _normalize_requires\n",
      "  \u001b[31m   \u001b[0m     self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io in /opt/conda/lib/python3.10/site-packages (0.31.0)\n",
      "Loaded model from checkpoint\n",
      "<unknown>\n",
      "<unknown>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_1/2447842573.py\", line 483, in parse_example  *\n        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 135, in tile_image  *\n        fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 117, in pad_to_multiple  *\n        height, width, channels = image.shape\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 766\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     input_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://tf_records_bucket/tf_records/Untitled Folder/\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# make sure / is there at the end,\u001b[39;00m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbucket_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_records_bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    764\u001b[0m     }  \u001b[38;5;66;03m# makesure there is a slash at the end of the path  # Choose an appropriate batch size\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# ! tensorboard --logdir gs://tf_records_bucket/tf_records/Untitled\\ Folder/logs/ \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 649\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m img_size \u001b[38;5;241m=\u001b[39m (patch_height, patch_width)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# get the train and test datasets\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain and Valid datasets are created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# create img_size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 523\u001b[0m, in \u001b[0;36mtrain_test_datasets\u001b[0;34m(input_directory, patch_height, patch_width, image_channels, label_channels, threshold_percentage, batch_size)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_datasets\u001b[39m(\n\u001b[1;32m    514\u001b[0m     input_directory,\n\u001b[1;32m    515\u001b[0m     patch_height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m     batch_size,\n\u001b[1;32m    521\u001b[0m ):\n\u001b[1;32m    522\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(input_directory)\n\u001b[0;32m--> 523\u001b[0m     image_patch_tensors_list, label_patch_tensors_list \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# Combine images and labels from different pairs\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(image_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 495\u001b[0m, in \u001b[0;36mparsing\u001b[0;34m(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampled_image_patches, sampled_label_patches\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Apply the parse_example function to each element in the dataset\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m parsed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m image_patch_tensors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    498\u001b[0m label_patch_tensors_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    233\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    235\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    168\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 169\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqnfsylz7.py:20\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__parse_example\u001b[0;34m(parsed_example)\u001b[0m\n\u001b[1;32m     18\u001b[0m label \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mto_dense, (ag__\u001b[38;5;241m.\u001b[39mld(parsed_example)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(label_shape)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(bandwise_normalize), (ag__\u001b[38;5;241m.\u001b[39mld(image),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 20\u001b[0m image_patches \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m label_patches \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tile_image), (ag__\u001b[38;5;241m.\u001b[39mld(label), ag__\u001b[38;5;241m.\u001b[39mld(label_channels), ag__\u001b[38;5;241m.\u001b[39mld(patch_height), ag__\u001b[38;5;241m.\u001b[39mld(patch_width)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     22\u001b[0m (sampled_mask, _) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(sampling), (ag__\u001b[38;5;241m.\u001b[39mld(label_patches), ag__\u001b[38;5;241m.\u001b[39mld(threshold_percentage)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filet1xhjd_6.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tile_image\u001b[0;34m(fullimg, CHANNELS, TILE_HT, TILE_WD)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(fullimg)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m fullimg \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_to_multiple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTILE_HT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTILE_WD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m images \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(fullimg),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[1;32m     13\u001b[0m tiles \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mextract_patches, (), \u001b[38;5;28mdict\u001b[39m(images\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(images), sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), \u001b[38;5;241m1\u001b[39m], strides\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), \u001b[38;5;241m1\u001b[39m], rates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileia31653p.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__pad_to_multiple\u001b[0;34m(image, TILE_HT, TILE_WD)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(image)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m (height, width, channels) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(image)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     12\u001b[0m target_height \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil, (ag__\u001b[38;5;241m.\u001b[39mld(height) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m target_width \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil, (ag__\u001b[38;5;241m.\u001b[39mld(width) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:929\u001b[0m, in \u001b[0;36mTensorShape.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns `self.dims` if the rank is known, otherwise raises ValueError.\"\"\"\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a shape with unknown rank.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_1/2447842573.py\", line 483, in parse_example  *\n        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 135, in tile_image  *\n        fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 117, in pad_to_multiple  *\n        height, width, channels = image.shape\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install Pillow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# metrics_results = compute_metrics(new_ground_truth, new_predict)\n",
    "\n",
    "\n",
    "# metrics_results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "class_colors = {\n",
    "        1: ( 5, 5, 230),\n",
    "        2: (190, 60, 15),\n",
    "        3: (65, 240, 125),\n",
    "        4: (105, 200, 95),\n",
    "        5: ( 30, 115, 10),\n",
    "        6: ( 255, 196, 34),\n",
    "        7: (110, 85, 5),\n",
    "        8: ( 235, 235, 220),\n",
    "        9: (120, 216, 47),\n",
    "        10: ( 84, 142, 128),\n",
    "        11: ( 84, 142, 128),\n",
    "        12: ( 84, 142, 128),\n",
    "        13: ( 50, 255, 215),\n",
    "        14: ( 50, 255, 215),\n",
    "        15: ( 50, 255, 215),\n",
    "        16: ( 193, 255, 0),\n",
    "        17: ( 105, 200, 95),\n",
    "        18: (105, 200, 95),\n",
    "        19: ( 105, 200, 95),\n",
    "        20: (193, 255, 0),\n",
    "        21: ( 255, 50, 185),\n",
    "        22: (255, 255, 255),\n",
    "}\n",
    "\n",
    "# Create a colormap using the class-color mapping\n",
    "colors = [class_colors[i] for i in range(1, 23)]\n",
    "normalized_colors_array = np.array([tuple(np.array(v) / 255.0) for v in class_colors.values()])\n",
    "\n",
    "cmap_image = ListedColormap(normalized_colors_array)\n",
    "\n",
    "\n",
    "\n",
    "class CustomMetricsCSVLogger(Callback):\n",
    "    def __init__(self, filename, separator=',', append=True):\n",
    "        super(CustomMetricsCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.append_header = True\n",
    "        self.max_epoch = 0  # Track the highest epoch number encountered\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Initialize min and max class-wise IOU at the beginning of each epoch\n",
    "        self.min_class_wise_iou = 100\n",
    "        self.max_class_wise_iou = 0\n",
    "\n",
    "        # Check if the file exists in Cloud Storage, if not, create it\n",
    "        if not self.file_exists():\n",
    "            self.create_file()\n",
    "\n",
    "    def file_exists(self):\n",
    "        # Check if the file exists in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        return blob.exists()\n",
    "\n",
    "    def create_file(self):\n",
    "        # Create the file in Cloud Storage and write the header\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Write the header to the blob\n",
    "        header = 'epoch,loss,val_loss,class_wise_iou,class_wise_dice_score,class_wise_accuracy,class_wise_precision,class_wise_recall,mean_iou,min_class_wise_iou,max_class_wise_iou\\n'\n",
    "        blob.upload_from_string(header)\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "\n",
    "        # Extract class-wise IOU\n",
    "        class_wise_iou = logs.get('class_wise_iou', 0.0)\n",
    "\n",
    "        # Update min and max class-wise IOU\n",
    "        self.min_class_wise_iou = min(self.min_class_wise_iou, class_wise_iou)\n",
    "        self.max_class_wise_iou = max(self.max_class_wise_iou, class_wise_iou)\n",
    "\n",
    "        # Append the row to the file in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download existing content\n",
    "        existing_content = blob.download_as_text() if blob.exists() else \"\"\n",
    "\n",
    "        # Extract metrics values from logs\n",
    "        metrics_values = [str(logs[key]) for key in ['loss', 'val_loss', 'class_wise_iou', 'class_wise_dice_score',\n",
    "                                                    'class_wise_accuracy', 'class_wise_precision', 'class_wise_recall', 'mean_iou']]\n",
    "\n",
    "        # Check if metrics for the current epoch already exist\n",
    "        epoch_exists = any(f\"{epoch},\" in line for line in existing_content.split('\\n'))\n",
    "\n",
    "        # If the file is empty or epoch entry doesn't exist, append the metrics\n",
    "        if not existing_content or not epoch_exists:\n",
    "            updated_content = existing_content + f\"{epoch},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "        else:\n",
    "            # Get the maximum epoch number in the existing content\n",
    "            max_existing_epoch = max(\n",
    "                int(line.split(',')[0]) for line in existing_content.split('\\n') if line.strip() and not line.startswith('epoch')\n",
    "            )\n",
    "\n",
    "            # Increment the epoch for the new entries\n",
    "            updated_content = existing_content + f\"{max_existing_epoch + 1},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "\n",
    "        # Update the highest epoch number\n",
    "        self.max_epoch = max(self.max_epoch, epoch)\n",
    "\n",
    "        # Upload updated content\n",
    "        blob.upload_from_string(updated_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class PredictSegmentationCallback(Callback):\n",
    "    def __init__(self, test_image_path, output_save_path):\n",
    "        super(PredictSegmentationCallback, self).__init__()\n",
    "        self.test_image_path = test_image_path\n",
    "        self.output_save_path = output_save_path\n",
    "        self.last_predicted_array = None\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     # Call your prediction function\n",
    "    #     self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "    #     normalized_array_image = self.last_predicted_array / (np.max(self.last_predicted_array) + 1e-10)\n",
    "    #     # Display the predicted array with the specified colormap\n",
    "    #     # plt.figure(figsize=(8, 4))\n",
    "    #     # plt.imshow(normalized_array_image, cmap=cmap_image)  # Adjust the colormap as needed\n",
    "    #     # plt.title(f'Predicted Array - Epoch {epoch}')\n",
    "    #     # plt.show()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            # Save the predicted array every 20 epochs\n",
    "            # Convert NumPy array to PIL Image\n",
    "            self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "            pil_image = Image.fromarray((self.last_predicted_array * 255).astype(np.uint8))\n",
    "\n",
    "            # Apply the colormap to the PIL Image\n",
    "            pil_image_colored = pil_image.convert('P', palette=Image.ADAPTIVE, colors=len(class_colors))\n",
    "            pil_image_colored.putpalette(np.array(normalized_colors_array * 255, dtype=np.uint8).flatten())\n",
    "\n",
    "            # Extract image name from the test_image_path for Google Cloud Storage\n",
    "            image_name = os.path.basename(self.test_image_path)\n",
    "\n",
    "            # Create the full GCS path for saving the predicted array as an image\n",
    "            gcs_content_save_path = f'{self.output_save_path}/output_epoch_{epoch}_{image_name}.png'\n",
    "\n",
    "            # Upload the image directly to GCS\n",
    "            storage_client = storage.Client()\n",
    "            bucket_name, blob_name = self.parse_gcs_path(gcs_content_save_path)\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Save the PIL Image to a BytesIO object\n",
    "            image_io = io.BytesIO()\n",
    "            pil_image_colored.save(image_io, format='PNG')\n",
    "\n",
    "            image_io.seek(0)\n",
    "\n",
    "            # Upload the image content to GCS\n",
    "            blob.upload_from_file(image_io, content_type='image/png')  # Set the correct content type\n",
    "\n",
    "            print(f'Predicted array saved at: {gcs_content_save_path}')\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "# from python_files.model_file import get_model\n",
    "import json\n",
    "from datetime import datetime\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "# def load_config(file_path):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         config = json.load(f)\n",
    "#     return config\n",
    "\n",
    "# config = load_config('./python_files/config.json')\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files).map(parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# # pre-processing functions\n",
    "# def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "#     # Convert the input_tensor to a float32 type\n",
    "#     input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "\n",
    "#     # Calculate the minimum and maximum values along the channel axis\n",
    "#     min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "#     max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "\n",
    "#     # Check for potential numerical instability\n",
    "#     denom = max_val - min_val\n",
    "#     denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "\n",
    "#     # Normalize the tensor band-wise to the range [0, 1]\n",
    "#     normalized_tensor = (input_tensor - min_val) / denom\n",
    "\n",
    "#     return normalized_tensor\n",
    "\n",
    "\n",
    "# def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "#     # Get the current dimensions\n",
    "#     height, width, channels = image.shape\n",
    "\n",
    "#     # Calculate the target dimensions\n",
    "#     target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "#     target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "\n",
    "#     # Calculate the amount of padding\n",
    "#     pad_height = target_height - height\n",
    "#     pad_width = target_width - width\n",
    "\n",
    "#     # Pad the image\n",
    "#     padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "\n",
    "#     return padded_image\n",
    "\n",
    "\n",
    "# def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "#     fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "#     images = tf.expand_dims(fullimg, axis=0)\n",
    "#     tiles = tf.image.extract_patches(\n",
    "#         images=images,\n",
    "#         sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "#         strides=[1, TILE_HT, TILE_WD, 1],\n",
    "#         rates=[1, 1, 1, 1],\n",
    "#         padding=\"VALID\",\n",
    "#     )\n",
    "\n",
    "#     tiles = tf.squeeze(tiles, axis=0)\n",
    "#     nrows = tiles.shape[0]\n",
    "#     ncols = tiles.shape[1]\n",
    "#     tiles = tf.reshape(tiles, [nrows, ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "#     return tiles\n",
    "\n",
    "\n",
    "# def sampling(label_image, threshold_percentage=99.9):\n",
    "#     num_zeros = tf.reduce_sum(\n",
    "#         tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "#     )\n",
    "\n",
    "#     # Calculate the total number of elements in each patch\n",
    "#     total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "\n",
    "#     # Calculate the percentage of zeros in each patch\n",
    "#     percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "\n",
    "#     boolean_mask = percentage_zeros <= threshold_percentage\n",
    "#     # Apply the threshold logic\n",
    "#     sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "#     return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "# def one_hot_encoding(label_tensor):\n",
    "#     # Assuming your pixel values are float labels\n",
    "#     float_labels = tf.squeeze(\n",
    "#         label_tensor, axis=-1\n",
    "#     )  # Assuming channel dimension is the last one\n",
    "\n",
    "#     # Determine the number of classes dynamically\n",
    "#     num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "\n",
    "#     # One-hot encode each image\n",
    "#     one_hot_encoded_images = tf.one_hot(\n",
    "#         tf.dtypes.cast(float_labels, tf.int32), depth=num_classes\n",
    "#     )\n",
    "\n",
    "#     # Print the shape of the resulting tensor and the number of classes\n",
    "#     # print(\"Shape of one-hot encoded images:\", one_hot_encoded_images.shape)\n",
    "#     # print(\"Number of classes:\", num_classes)\n",
    "\n",
    "#     return one_hot_encoded_images\n",
    "\n",
    "\n",
    "\n",
    "# # @tf.function\n",
    "# def parse_example(parsed_example, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "#     image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "#     image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "#     label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "#     label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "#     print(image_shape)\n",
    "#     print(parsed_example[\"image_shape\"])\n",
    "#     # image normalization\n",
    "#     image = bandwise_normalize(image)\n",
    "\n",
    "#     # image and label patching\n",
    "#     image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "#     label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "#     # sampling\n",
    "#     sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "#     sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "#     sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "#     # one-hot encoding\n",
    "#     sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "#     return sampled_image_patches, sampled_label_patches\n",
    "\n",
    "# def parsing(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "#     image_patch_tensors_list = []\n",
    "#     label_patch_tensors_list = []\n",
    "#     for parsed_example in dataset:\n",
    "#         sampled_image_patches, sampled_label_patches = parse_example(parsed_example, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\n",
    "#         image_patch_tensors_list.append(sampled_image_patches)\n",
    "#         label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "#     return image_patch_tensors_list, label_patch_tensors_list\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom pre-processing functions\n",
    "@tf.function\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "    return normalized_tensor\n",
    "\n",
    "@tf.function\n",
    "# def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "#     height, width, channels = image.shape\n",
    "#     target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "#     target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "#     padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "#     return padded_image\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    target_height = tf.cast(tf.math.ceil(tf.shape(image)[0] / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(tf.shape(image)[1] / TILE_WD) * TILE_WD, tf.int32)\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    return padded_image\n",
    "\n",
    "@tf.function\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    # Cast elements to a supported data type\n",
    "    tiles = tf.cast(tiles, tf.float32)\n",
    "    \n",
    "    # Reshape without specifying batch size dimensions\n",
    "    tiles_shape = tf.shape(tiles)\n",
    "    tiles = tf.reshape(tiles, [tiles_shape[0], tiles_shape[1], TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "@tf.function\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4])\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    return boolean_mask, tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "\n",
    "@tf.function\n",
    "def one_hot_encoding(label_tensor):\n",
    "    float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "    one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "# Optimized parsing function using tf.data.Dataset\n",
    "def parsing(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "    def parse_example(parsed_example):\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "        \n",
    "        image = bandwise_normalize(image)\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "        \n",
    "        sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "        \n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "        \n",
    "        return sampled_image_patches, sampled_label_patches\n",
    "\n",
    "    # Apply the parse_example function to each element in the dataset\n",
    "    parsed_dataset = dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "\n",
    "    for image_patches, label_patches in parsed_dataset:\n",
    "\n",
    "        # Append to lists\n",
    "        image_patch_tensors_list.append(image_patches)\n",
    "        label_patch_tensors_list.append(label_patches)\n",
    "        \n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "\n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "):\n",
    "    dataset = create_dataset(input_directory)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "\n",
    "    # Combine images and labels from different pairs\n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "config = load_config('./pipeline_scripts/config.json')\n",
    "from google.cloud import storage\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.python.lib.io import file_io\n",
    "# Convert img_size to a tuple\n",
    "config[\"img_size\"] = tuple(config[\"img_size\"])\n",
    "\n",
    "# Now you can access the config values normally\n",
    "model_path = config.get(\"model_path\")\n",
    "model_name = config.get(\"model_name\")\n",
    "test_image_path = config.get(\"test_image_path\")\n",
    "img_size = config.get(\"img_size\")\n",
    "num_bands = config.get(\"num_bands\")\n",
    "num_classes = config.get(\"num_classes\")\n",
    "gcs_path = config.get(\"google_storage_path\")\n",
    "\n",
    "\n",
    "# Load the model if a checkpoint exists\n",
    "# Load the model if a checkpoint exists\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='gislogics')  # Set up GCS connection\n",
    "\n",
    "if tf.io.gfile.exists(model_path):  # Accurately check for file existence in GCS\n",
    "    # Load existing model\n",
    "    model = load_model(model_path)  # Handle GCS authentication here if needed\n",
    "    print(\"Loaded model from checkpoint\")\n",
    "else:\n",
    "    # If no checkpoint exists, create a new model\n",
    "    model = get_model(\n",
    "        img_size=img_size, num_classes=num_classes, num_bands=num_bands\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    print(\"Created a new model\")\n",
    "\n",
    "    # # Save the new model to the model_path in GCS\n",
    "    save_model(model, model_path)\n",
    "    print(\"Saved new model to:\", model_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Continue training\n",
    "from pipeline_scripts.eval import *\n",
    "from pipeline_scripts.prediction import *\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")\n",
    "    \n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "    img_size = (patch_height, patch_width)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        input_directory,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "    )\n",
    "    \n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "    # create img_size\n",
    "    model = get_model(\n",
    "        img_size= img_size, \n",
    "        num_classes=num_classes, \n",
    "        num_bands=image_channels\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # compilation of model, with custom metric\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=[np.mean(compute_metrics(new_ground_truth, new_predict)[0])]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Early stopping after 5 epochs \n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,  \n",
    "    restore_best_weights=True,  \n",
    "    verbose=1  \n",
    "    )\n",
    "    \n",
    "    # Agroforestry Class\n",
    "    Agroforestry = 18\n",
    "    \n",
    "    # including custom metrics in callbacks\n",
    "    custom_metrics_callback = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logs.update({\n",
    "        \"class_wise_iou\": compute_metrics(new_ground_truth, new_predict)[0][Agroforestry],\n",
    "        \"class_wise_dice_score\": compute_metrics(new_ground_truth, new_predict)[1][Agroforestry],\n",
    "        \"class_wise_accuracy\": compute_metrics(new_ground_truth, new_predict)[2][Agroforestry],\n",
    "        \"class_wise_precision\": compute_metrics(new_ground_truth, new_predict)[3][Agroforestry],\n",
    "        \"class_wise_recall\": compute_metrics(new_ground_truth, new_predict)[4][Agroforestry],\n",
    "        \"mean_iou\": compute_metrics(new_ground_truth, new_predict)[5],\n",
    "        \"min_class_wise_iou\": np.min(metrics_results[0]),\n",
    "        \"max_class_wise_iou\": np.max(metrics_results[0]),\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": logs[\"loss\"],\n",
    "        \"val_loss\": logs[\"val_loss\"]}))\n",
    "\n",
    "    \n",
    "    # callbacks and logging\n",
    "    csv_logger = keras.callbacks.CSVLogger(\n",
    "    input_directory + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "    append=True\n",
    "    )\n",
    "\n",
    "    custom_metrics_csv_logger = CustomMetricsCSVLogger(\n",
    "        input_params[\"input_directory\"] + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "        append=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"gs://tf_records_bucket/tf_records/Untitled Folder/logs/\"  # Specify the directory to save logs\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    output_of_image = \"gs://tf_records_bucket/tf_records/Untitled Folder/output\"\n",
    "    \n",
    "    # Combine all callbacks\n",
    "    all_callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(model_path + model_name, save_best_only=False),\n",
    "        tensorboard_callback,\n",
    "        custom_metrics_callback,\n",
    "        custom_metrics_csv_logger,  # Add the custom_metrics_csv_logger here\n",
    "        # early_stopping,\n",
    "        PredictSegmentationCallback(test_image_path, output_of_image)\n",
    "    ]\n",
    "\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=3,\n",
    "        callbacks=all_callbacks,\n",
    "        batch_size=32,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped at epoch {early_stopping.stopped_epoch} due to early stopping.\")\n",
    "    else:\n",
    "        print(\"Training completed all epochs.\")\n",
    "    # Save the model after training\n",
    "    # model.save(model_path + model_name)\n",
    "    # print(\"Model saved locally\")\n",
    "\n",
    "    upload_blob(gcs_path)\n",
    "    print(\"Uploaded to cloud storage successfully\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ! tensorboard --logdir gs://tf_records_bucket/tf_records/Untitled\\ Folder/logs/ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b81dfb7-63b6-438c-b03c-4b8b49151097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 14:34:22.000097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-07 14:34:22.000352: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [11]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Valid datasets are created\n"
     ]
    }
   ],
   "source": [
    "# input_params = {\n",
    "#         \"input_directory\": \"gs://tf_records_bucket/tf_records/\",  # make sure / is there at the end,\n",
    "#         \"image_names\": [], # \"area2_0530_2022_8bands.tif\", \"area2_0909_2023_composite.tif\", \"area2_0911_2023_8bands.tif\"\n",
    "#         \"bucket_name\": \"tf_records_bucket\",\n",
    "#         \"threshold_percentage\": 99.9,\n",
    "#         \"image_channels\": 8,  # 8 bands images as input\n",
    "#         \"label_channels\": 1,\n",
    "#         \"patch_height\": 8,\n",
    "#         \"patch_width\": 8,\n",
    "#         \"batch_size\": 32, \n",
    "#         # \"model_path\": \"trained_model/\",\n",
    "#     }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "# train(**input_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e9ae9f-7c5f-42cf-83fd-4450c1795915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/eval_and_pred\n"
     ]
    }
   ],
   "source": [
    "# %cd /home/jupyter/eval_and_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a2c00-28d3-4f37-8720-e7dc40b32f13",
   "metadata": {},
   "source": [
    "# **Leftover Code from EVAL and PRED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ad6fea-2823-45c0-be6e-1b19d8a36abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /opt/conda/lib/python3.10/site-packages (1.3.9)\n",
      "Requirement already satisfied: affine in /opt/conda/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2023.11.17)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.23.5)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from rasterio) (68.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (0.14.3)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n",
      "Loaded model from checkpoint\n",
      "TFRecords List: ['gs://tf_records_bucket/tf_records/Untitled Folder/area2_0123_2023_8bands_tfrecord.tfrecord', 'gs://tf_records_bucket/tf_records/Untitled Folder/area2_0617_2023_8bands_tfrecord.tfrecord']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 07:53:30.224563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: {'image': SparseTensor(indices=tf.Tensor(\n",
      "[[        0]\n",
      " [        1]\n",
      " [        2]\n",
      " ...\n",
      " [135436813]\n",
      " [135436814]\n",
      " [135436815]], shape=(135436816, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(135436816,), dtype=float32), dense_shape=tf.Tensor([135436816], shape=(1,), dtype=int64)), 'image_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    8], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64)), 'label': SparseTensor(indices=tf.Tensor(\n",
      "[[       0]\n",
      " [       1]\n",
      " [       2]\n",
      " ...\n",
      " [16929599]\n",
      " [16929600]\n",
      " [16929601]], shape=(16929602, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(16929602,), dtype=float32), dense_shape=tf.Tensor([16929602], shape=(1,), dtype=int64)), 'label_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    1], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64))}\n",
      "Dataset: {'image': SparseTensor(indices=tf.Tensor(\n",
      "[[        0]\n",
      " [        1]\n",
      " [        2]\n",
      " ...\n",
      " [135436813]\n",
      " [135436814]\n",
      " [135436815]], shape=(135436816, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(135436816,), dtype=float32), dense_shape=tf.Tensor([135436816], shape=(1,), dtype=int64)), 'image_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    8], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64)), 'label': SparseTensor(indices=tf.Tensor(\n",
      "[[       0]\n",
      " [       1]\n",
      " [       2]\n",
      " ...\n",
      " [16929599]\n",
      " [16929600]\n",
      " [16929601]], shape=(16929602, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(16929602,), dtype=float32), dense_shape=tf.Tensor([16929602], shape=(1,), dtype=int64)), 'label_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    1], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64))}\n",
      "parsed_example {'image': SparseTensor(indices=tf.Tensor(\n",
      "[[        0]\n",
      " [        1]\n",
      " [        2]\n",
      " ...\n",
      " [135436813]\n",
      " [135436814]\n",
      " [135436815]], shape=(135436816, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(135436816,), dtype=float32), dense_shape=tf.Tensor([135436816], shape=(1,), dtype=int64)), 'image_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    8], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64)), 'label': SparseTensor(indices=tf.Tensor(\n",
      "[[       0]\n",
      " [       1]\n",
      " [       2]\n",
      " ...\n",
      " [16929599]\n",
      " [16929600]\n",
      " [16929601]], shape=(16929602, 1), dtype=int64), values=tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(16929602,), dtype=float32), dense_shape=tf.Tensor([16929602], shape=(1,), dtype=int64)), 'label_shape': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    1], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64))}\n",
      "parsed_example[\"image_shape\"] SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [2]], shape=(3, 1), dtype=int64), values=tf.Tensor([3694 4583    8], shape=(3,), dtype=int64), dense_shape=tf.Tensor([3], shape=(1,), dtype=int64))\n",
      "image shape in parse example tf.Tensor([3694 4583    8], shape=(3,), dtype=int64)\n",
      "Bandwise Norm Image Shape: (3694, 4583, 8)\n",
      "(3694, 4583, 8)\n",
      "(3694, 4583, 8)\n",
      "(3694, 4583, 1)\n",
      "(3694, 4583, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_1/3359277659.py\", line 345, in sampling  *\n        num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, tf.constant(0, dtype=tf.float32)), tf.float32), axis=[2, 3, 4])\n\n    TypeError: Expected float32, but got (3696, 4584, 1) of type 'TensorShape'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 662\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    648\u001b[0m     input_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://tf_records_bucket/tf_records/Untitled Folder/\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# make sure / is there at the end,\u001b[39;00m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbucket_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_records_bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m     }  \u001b[38;5;66;03m# makesure there is a slash at the end of the path  # Choose an appropriate batch size\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# ! tensorboard --logdir gs://tf_records_bucket/tf_records/Untitled\\ Folder/logs/ \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 544\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m image_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# img_size = (patch_height, patch_width)\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# get the train and test datasets\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_tfrecords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_names\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain and Valid datasets are created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# create img_size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 435\u001b[0m, in \u001b[0;36mtrain_test_datasets\u001b[0;34m(input_directory, patch_height, patch_width, image_channels, label_channels, threshold_percentage, batch_size, image_names)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_datasets\u001b[39m(\n\u001b[1;32m    425\u001b[0m     input_directory,\n\u001b[1;32m    426\u001b[0m     patch_height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m     image_names\n\u001b[1;32m    433\u001b[0m ):\n\u001b[1;32m    434\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(input_directory, image_names)\n\u001b[0;32m--> 435\u001b[0m     image_patch_tensors_list, label_patch_tensors_list \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# Combine images and labels from different pairs\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(image_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 389\u001b[0m, in \u001b[0;36mparsing\u001b[0;34m(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\u001b[0m\n\u001b[1;32m    387\u001b[0m label_patch_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parsed_data \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m--> 389\u001b[0m     sampled_image_patches, sampled_label_patches \u001b[38;5;241m=\u001b[39m \u001b[43mparse_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     image_patch_tensors\u001b[38;5;241m.\u001b[39mappend(sampled_image_patches)\n\u001b[1;32m    391\u001b[0m     label_patch_tensors\u001b[38;5;241m.\u001b[39mappend(sampled_label_patches)\n",
      "Cell \u001b[0;32mIn[18], line 374\u001b[0m, in \u001b[0;36mparsing.<locals>.parse_example\u001b[0;34m(parsed_example)\u001b[0m\n\u001b[1;32m    371\u001b[0m image_patches \u001b[38;5;241m=\u001b[39m tile_image(image, image_channels, patch_height, patch_width)\n\u001b[1;32m    372\u001b[0m label_patches \u001b[38;5;241m=\u001b[39m tile_image(label, label_channels, patch_height, patch_width)\n\u001b[0;32m--> 374\u001b[0m sampled_mask, _ \u001b[38;5;241m=\u001b[39m \u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m sampled_image_patches \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(image_patches, sampled_mask)\n\u001b[1;32m    376\u001b[0m sampled_label_patches \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(label_patches, sampled_mask)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filerz_kxeb6.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__sampling\u001b[0;34m(label_image, threshold_percentage)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m num_zeros \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_sum, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m, ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]), fscope)\n\u001b[1;32m     11\u001b[0m total_elements \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_prod, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(label_image),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m2\u001b[39m:],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m percentage_zeros \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(num_zeros) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(total_elements) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_1/3359277659.py\", line 345, in sampling  *\n        num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, tf.constant(0, dtype=tf.float32)), tf.float32), axis=[2, 3, 4])\n\n    TypeError: Expected float32, but got (3696, 4584, 1) of type 'TensorShape'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install Pillow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# metrics_results = compute_metrics(new_ground_truth, new_predict)\n",
    "\n",
    "\n",
    "# metrics_results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "class_colors = {\n",
    "        1: ( 5, 5, 230),\n",
    "        2: (190, 60, 15),\n",
    "        3: (65, 240, 125),\n",
    "        4: (105, 200, 95),\n",
    "        5: ( 30, 115, 10),\n",
    "        6: ( 255, 196, 34),\n",
    "        7: (110, 85, 5),\n",
    "        8: ( 235, 235, 220),\n",
    "        9: (120, 216, 47),\n",
    "        10: ( 84, 142, 128),\n",
    "        11: ( 84, 142, 128),\n",
    "        12: ( 84, 142, 128),\n",
    "        13: ( 50, 255, 215),\n",
    "        14: ( 50, 255, 215),\n",
    "        15: ( 50, 255, 215),\n",
    "        16: ( 193, 255, 0),\n",
    "        17: ( 105, 200, 95),\n",
    "        18: (105, 200, 95),\n",
    "        19: ( 105, 200, 95),\n",
    "        20: (193, 255, 0),\n",
    "        21: ( 255, 50, 185),\n",
    "        22: (255, 255, 255),\n",
    "}\n",
    "\n",
    "# Create a colormap using the class-color mapping\n",
    "colors = [class_colors[i] for i in range(1, 23)]\n",
    "normalized_colors_array = np.array([tuple(np.array(v) / 255.0) for v in class_colors.values()])\n",
    "\n",
    "cmap_image = ListedColormap(normalized_colors_array)\n",
    "\n",
    "\n",
    "\n",
    "class CustomMetricsCSVLogger(Callback):\n",
    "    def __init__(self, filename, separator=',', append=True):\n",
    "        super(CustomMetricsCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.append_header = True\n",
    "        self.max_epoch = 0  # Track the highest epoch number encountered\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Initialize min and max class-wise IOU at the beginning of each epoch\n",
    "        self.min_class_wise_iou = 100\n",
    "        self.max_class_wise_iou = 0\n",
    "\n",
    "        # Check if the file exists in Cloud Storage, if not, create it\n",
    "        if not self.file_exists():\n",
    "            self.create_file()\n",
    "\n",
    "    def file_exists(self):\n",
    "        # Check if the file exists in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        return blob.exists()\n",
    "\n",
    "    def create_file(self):\n",
    "        # Create the file in Cloud Storage and write the header\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Write the header to the blob\n",
    "        header = 'epoch,loss,val_loss,class_wise_iou,class_wise_dice_score,class_wise_accuracy,class_wise_precision,class_wise_recall,mean_iou,min_class_wise_iou,max_class_wise_iou\\n'\n",
    "        blob.upload_from_string(header)\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "\n",
    "        # Extract class-wise IOU\n",
    "        class_wise_iou = logs.get('class_wise_iou', 0.0)\n",
    "\n",
    "        # Update min and max class-wise IOU\n",
    "        self.min_class_wise_iou = min(self.min_class_wise_iou, class_wise_iou)\n",
    "        self.max_class_wise_iou = max(self.max_class_wise_iou, class_wise_iou)\n",
    "\n",
    "        # Append the row to the file in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download existing content\n",
    "        existing_content = blob.download_as_text() if blob.exists() else \"\"\n",
    "\n",
    "        # Extract metrics values from logs\n",
    "        metrics_values = [str(logs[key]) for key in ['loss', 'val_loss', 'class_wise_iou', 'class_wise_dice_score',\n",
    "                                                    'class_wise_accuracy', 'class_wise_precision', 'class_wise_recall', 'mean_iou']]\n",
    "\n",
    "        # Check if metrics for the current epoch already exist\n",
    "        epoch_exists = any(f\"{epoch},\" in line for line in existing_content.split('\\n'))\n",
    "\n",
    "        # If the file is empty or epoch entry doesn't exist, append the metrics\n",
    "        if not existing_content or not epoch_exists:\n",
    "            updated_content = existing_content + f\"{epoch},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "        else:\n",
    "            # Get the maximum epoch number in the existing content\n",
    "            max_existing_epoch = max(\n",
    "                int(line.split(',')[0]) for line in existing_content.split('\\n') if line.strip() and not line.startswith('epoch')\n",
    "            )\n",
    "\n",
    "            # Increment the epoch for the new entries\n",
    "            updated_content = existing_content + f\"{max_existing_epoch + 1},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "\n",
    "        # Update the highest epoch number\n",
    "        self.max_epoch = max(self.max_epoch, epoch)\n",
    "\n",
    "        # Upload updated content\n",
    "        blob.upload_from_string(updated_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class PredictSegmentationCallback(Callback):\n",
    "    def __init__(self, test_image_path, output_save_path):\n",
    "        super(PredictSegmentationCallback, self).__init__()\n",
    "        self.test_image_path = test_image_path\n",
    "        self.output_save_path = output_save_path\n",
    "        self.last_predicted_array = None\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     # Call your prediction function\n",
    "    #     self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "    #     normalized_array_image = self.last_predicted_array / (np.max(self.last_predicted_array) + 1e-10)\n",
    "    #     # Display the predicted array with the specified colormap\n",
    "    #     # plt.figure(figsize=(8, 4))\n",
    "    #     # plt.imshow(normalized_array_image, cmap=cmap_image)  # Adjust the colormap as needed\n",
    "    #     # plt.title(f'Predicted Array - Epoch {epoch}')\n",
    "    #     # plt.show()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            # Save the predicted array every 20 epochs\n",
    "            # Convert NumPy array to PIL Image\n",
    "            self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "            pil_image = Image.fromarray((self.last_predicted_array * 255).astype(np.uint8))\n",
    "\n",
    "            # Apply the colormap to the PIL Image\n",
    "            pil_image_colored = pil_image.convert('P', palette=Image.ADAPTIVE, colors=len(class_colors))\n",
    "            pil_image_colored.putpalette(np.array(normalized_colors_array * 255, dtype=np.uint8).flatten())\n",
    "\n",
    "            # Extract image name from the test_image_path for Google Cloud Storage\n",
    "            image_name = os.path.basename(self.test_image_path)\n",
    "\n",
    "            # Create the full GCS path for saving the predicted array as an image\n",
    "            gcs_content_save_path = f'{self.output_save_path}/output_epoch_{epoch}_{image_name}.png'\n",
    "\n",
    "            # Upload the image directly to GCS\n",
    "            storage_client = storage.Client()\n",
    "            bucket_name, blob_name = self.parse_gcs_path(gcs_content_save_path)\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Save the PIL Image to a BytesIO object\n",
    "            image_io = io.BytesIO()\n",
    "            pil_image_colored.save(image_io, format='PNG')\n",
    "\n",
    "            image_io.seek(0)\n",
    "\n",
    "            # Upload the image content to GCS\n",
    "            blob.upload_from_file(image_io, content_type='image/png')  # Set the correct content type\n",
    "\n",
    "            print(f'Predicted array saved at: {gcs_content_save_path}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# imports================\n",
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from pipeline_scripts.model_file import get_model\n",
    "\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    # \"label\": tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    # \"label_shape\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    print(f\"TFRecords List: {tfrecord_files}\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files).map(parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "# pre-processing functions\n",
    "@tf.function\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "    return normalized_tensor\n",
    "\n",
    "@tf.function\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    if image.shape.rank is None:  # Check for unknown rank\n",
    "        try:\n",
    "            image = tf.expand_dims(image, axis=-1)  # Add a channel dimension if missing\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Image has an invalid rank\") from None\n",
    "    target_height = tf.cast(tf.math.ceil(tf.shape(image)[0] / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(tf.shape(image)[1] / TILE_WD) * TILE_WD, tf.int32)\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    return padded_image\n",
    "\n",
    "@tf.function\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    # Cast elements to a supported data type\n",
    "    tiles = tf.cast(tiles, tf.float32)\n",
    "    \n",
    "    # Reshape without specifying batch size dimensions\n",
    "    tiles_shape = tf.shape(tiles)\n",
    "    tiles = tf.reshape(tiles, [tiles_shape[0], tiles_shape[1], TILE_HT, TILE_WD, CHANNELS])\n",
    "    print(\"Output Tensor Rank:\", tf.rank(tiles))\n",
    "    return tiles\n",
    "\n",
    "@tf.function\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    # num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4])\n",
    "    num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, tf.constant(0, dtype=tf.float32)), tf.float32), axis=[2, 3, 4])\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    return boolean_mask, tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "\n",
    "@tf.function\n",
    "def one_hot_encoding(label_tensor):\n",
    "    float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "    one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "# Optimized parsing function using tf.data.Dataset\n",
    "def parsing(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "    def parse_example(parsed_example):\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        print(\"parsed_example\", parsed_example)\n",
    "        print('parsed_example[\"image_shape\"]', parsed_example[\"image_shape\"])\n",
    "        print(\"image shape in parse example\", image_shape)\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), tf.cast(image_shape, tf.int64))\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), tf.cast(label_shape, tf.int64))\n",
    "        \n",
    "        image = bandwise_normalize(image)\n",
    "        print(f\"Bandwise Norm Image Shape: {image.shape}\")\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "        \n",
    "        sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "        \n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "        \n",
    "        return sampled_image_patches, sampled_label_patches\n",
    "    \n",
    "    for d in dataset:\n",
    "        print(f\"Dataset: {d}\")\n",
    "\n",
    "      # Preprocessing within parsing loop for efficient memory usage\n",
    "    image_patch_tensors = []\n",
    "    label_patch_tensors = []\n",
    "    for parsed_data in dataset:\n",
    "        sampled_image_patches, sampled_label_patches = parse_example(parsed_data)\n",
    "        image_patch_tensors.append(sampled_image_patches)\n",
    "        label_patch_tensors.append(sampled_label_patches)\n",
    "\n",
    "      # Stack tensors for final output\n",
    "    # image_patch_tensors = tf.stack(image_patch_tensors)\n",
    "    # label_patch_tensors = tf.stack(label_patch_tensors)\n",
    "\n",
    "    return image_patch_tensors, label_patch_tensors\n",
    "#     # Apply the parse_example function to each element in the dataset\n",
    "#     parsed_dataset = dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "#     image_patch_tensors_list = []\n",
    "#     label_patch_tensors_list = []\n",
    "\n",
    "#     for image_patches, label_patches in parsed_dataset:\n",
    "\n",
    "#         # Append to lists\n",
    "#         image_patch_tensors_list.append(image_patches)\n",
    "#         label_patch_tensors_list.append(label_patches)\n",
    "        \n",
    "#     return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    image_names\n",
    "):\n",
    "    dataset = create_dataset(input_directory, image_names)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "\n",
    "    # Combine images and labels from different pairs\n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "    \n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "config = load_config('./pipeline_scripts/config.json')\n",
    "from google.cloud import storage\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.python.lib.io import file_io\n",
    "# Convert img_size to a tuple\n",
    "config[\"img_size\"] = tuple(config[\"img_size\"])\n",
    "\n",
    "# Now you can access the config values normally\n",
    "model_path = config.get(\"model_path\")\n",
    "model_name = config.get(\"model_name\")\n",
    "test_image_path = config.get(\"test_image_path\")\n",
    "img_size = config.get(\"img_size\")\n",
    "num_bands = config.get(\"num_bands\")\n",
    "num_classes = config.get(\"num_classes\")\n",
    "gcs_path = config.get(\"google_storage_path\")\n",
    "gcs_tfrecords = config.get(\"gcs_tfrecords\")\n",
    "\n",
    "\n",
    "# Load the model if a checkpoint exists\n",
    "# Load the model if a checkpoint exists\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='gislogics')  # Set up GCS connection\n",
    "\n",
    "if tf.io.gfile.exists(model_path):  # Accurately check for file existence in GCS\n",
    "    # Load existing model\n",
    "    model = load_model(model_path)  # Handle GCS authentication here if needed\n",
    "    print(\"Loaded model from checkpoint\")\n",
    "else:\n",
    "    # If no checkpoint exists, create a new model\n",
    "    model = get_model(\n",
    "        img_size=img_size, num_classes=num_classes, num_bands=num_bands\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    print(\"Created a new model\")\n",
    "\n",
    "    # # Save the new model to the model_path in GCS\n",
    "    save_model(model, model_path)\n",
    "    print(\"Saved new model to:\", model_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Continue training\n",
    "from pipeline_scripts.eval import *\n",
    "from pipeline_scripts.prediction import *\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")  \n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "\n",
    "    image_names = kwargs.get(\"image_names\")\n",
    "    # img_size = (patch_height, patch_width)\n",
    "    \n",
    "    \n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        gcs_tfrecords,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "    # create img_size\n",
    "    model = get_model(\n",
    "        img_size= img_size, \n",
    "        num_classes=num_classes, \n",
    "        num_bands=image_channels\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # compilation of model, with custom metric\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=[np.mean(compute_metrics(new_ground_truth, new_predict)[0])]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Early stopping after 5 epochs \n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,  \n",
    "    restore_best_weights=True,  \n",
    "    verbose=1  \n",
    "    )\n",
    "    \n",
    "    # Agroforestry Class\n",
    "    Agroforestry = 18\n",
    "    \n",
    "    # including custom metrics in callbacks\n",
    "    custom_metrics_callback = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logs.update({\n",
    "        \"class_wise_iou\": compute_metrics(new_ground_truth, new_predict)[0][Agroforestry],\n",
    "        \"class_wise_dice_score\": compute_metrics(new_ground_truth, new_predict)[1][Agroforestry],\n",
    "        \"class_wise_accuracy\": compute_metrics(new_ground_truth, new_predict)[2][Agroforestry],\n",
    "        \"class_wise_precision\": compute_metrics(new_ground_truth, new_predict)[3][Agroforestry],\n",
    "        \"class_wise_recall\": compute_metrics(new_ground_truth, new_predict)[4][Agroforestry],\n",
    "        \"mean_iou\": compute_metrics(new_ground_truth, new_predict)[5],\n",
    "        \"min_class_wise_iou\": np.min(metrics_results[0]),\n",
    "        \"max_class_wise_iou\": np.max(metrics_results[0]),\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": logs[\"loss\"],\n",
    "        \"val_loss\": logs[\"val_loss\"]}))\n",
    "\n",
    "    \n",
    "    # callbacks and logging\n",
    "    csv_logger = keras.callbacks.CSVLogger(\n",
    "    input_directory + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "    append=True\n",
    "    )\n",
    "\n",
    "    custom_metrics_csv_logger = CustomMetricsCSVLogger(\n",
    "        input_params[\"input_directory\"] + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "        append=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"gs://tf_records_bucket/tf_records/Untitled Folder/logs/\"  # Specify the directory to save logs\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    output_of_image = \"gs://tf_records_bucket/tf_records/Untitled Folder/output\"\n",
    "    \n",
    "    # Combine all callbacks\n",
    "    all_callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(model_path + model_name, save_best_only=False),\n",
    "        tensorboard_callback,\n",
    "        custom_metrics_callback,\n",
    "        custom_metrics_csv_logger,  # Add the custom_metrics_csv_logger here\n",
    "        # early_stopping,\n",
    "        PredictSegmentationCallback(test_image_path, output_of_image)\n",
    "    ]\n",
    "\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=3,\n",
    "        callbacks=all_callbacks,\n",
    "        batch_size=32,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped at epoch {early_stopping.stopped_epoch} due to early stopping.\")\n",
    "    else:\n",
    "        print(\"Training completed all epochs.\")\n",
    "    # Save the model after training\n",
    "    # model.save(model_path + model_name)\n",
    "    # print(\"Model saved locally\")\n",
    "\n",
    "    upload_blob(gcs_path)\n",
    "    print(\"Uploaded to cloud storage successfully\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_names\" : [],\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ! tensorboard --logdir gs://tf_records_bucket/tf_records/Untitled\\ Folder/logs/ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45139199-1447-4abd-824c-de084aee94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 04:58:26.948930: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at example_parsing_ops.cc:98 : INVALID_ARGUMENT: Key: label_shape.  Can't parse serialized Example.\n",
      "2024-03-09 04:58:26.953933: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: Key: label_shape.  Can't parse serialized Example.\n",
      "\t [[{{node ParseExample/ParseExampleV2}}]]\n"
     ]
    }
   ],
   "source": [
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from pipeline_scripts.model_file import get_model\n",
    "\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "    return normalized_tensor\n",
    "\n",
    "@tf.function\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    target_height = tf.cast(tf.math.ceil(tf.shape(image)[0] / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(tf.shape(image)[1] / TILE_WD) * TILE_WD, tf.int32)\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    return padded_image\n",
    "\n",
    "@tf.function\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    # Cast elements to a supported data type\n",
    "    tiles = tf.cast(tiles, tf.float32)\n",
    "    \n",
    "    # Reshape without specifying batch size dimensions\n",
    "    tiles_shape = tf.shape(tiles)\n",
    "    tiles = tf.reshape(tiles, [tiles_shape[0], tiles_shape[1], TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "@tf.function\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4])\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    return boolean_mask, tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "\n",
    "@tf.function\n",
    "def one_hot_encoding(label_tensor):\n",
    "    float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "    one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "# Optimized parsing function using tf.data.Dataset\n",
    "def parsing(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "    def parse_example(parsed_example):\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "        print(image_shape)\n",
    "        image = bandwise_normalize(image)\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "        \n",
    "        sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "        \n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "        \n",
    "        return sampled_image_patches, sampled_label_patches\n",
    "\n",
    "    # Apply the parse_example function to each element in the dataset\n",
    "    parsed_dataset = dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "\n",
    "    for image_patches, label_patches in parsed_dataset:\n",
    "\n",
    "        # Append to lists\n",
    "        image_patch_tensors_list.append(image_patches)\n",
    "        label_patch_tensors_list.append(label_patches)\n",
    "        \n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    image_names\n",
    "):\n",
    "    dataset = create_dataset(input_directory, image_names)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "\n",
    "    # Combine images and labels from different pairs\n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")\n",
    "    model_path = kwargs.get(\"model_path\")\n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "    image_names = kwargs.get(\"image_names\")\n",
    "    img_size = (patch_height, patch_width)\n",
    "    model_name = f\"patch_h{patch_height}_w{patch_width}_batch_{batch_size}_on_0609_2023_composite.hdf5\"\n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        input_directory,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "    # create img_size\n",
    "    model = get_model(\n",
    "        img_size=img_size, num_classes=num_classes, num_bands=image_channels\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(model_path + model_name, save_best_only=False),\n",
    "        keras.callbacks.CSVLogger(input_directory + \"logs/\" + f\"training_logs_{model_name}_single_file.csv\"),  # Add CSVLogger\n",
    "    ]\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=3,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=32,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "    model.save(model_path + model_name)\n",
    "    print(\"model saved locally\")\n",
    "\n",
    "    upload_blob(bucket_name, model_path + model_name, \"model/\" + model_name)\n",
    "    print(\"uploaded to cloud storage successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"image_names\": [],\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd73332-fa62-4c73-b243-0d0ef2697cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2023.11.17)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.23.5)\n",
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Using cached snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from rasterio) (68.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
      "Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Using cached snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.9 snuggs-1.4.7\n",
      "Collecting geopandas\n",
      "  Using cached geopandas-0.14.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas)\n",
      "  Using cached fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.3)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Using cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.23.5)\n",
      "Using cached geopandas-0.14.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl (15.7 MB)\n",
      "Using cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Installing collected packages: pyproj, fiona, geopandas\n",
      "Successfully installed fiona-1.9.6 geopandas-0.14.3 pyproj-3.6.1\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 13:06:34.958866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 13:06:45.055929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint\n",
      "prediction.clip_tiff, tiff gs://tf_records_bucket/labels/area2_0530_2022_8bands.tif\n",
      "(3694, 4560, 8)\n",
      "(3694, 4560, 8)\n",
      "dims (3696, 4560, 8)\n",
      "129/129 [==============================] - 9s 68ms/step\n",
      "Time taken for predictions: 10.997666597366333 seconds\n",
      "segmentation_patches_reshaped.shape (462, 570, 8, 8)\n",
      "row_indices_patch (462,)\n",
      "col_indices_patch (570,)\n",
      "stitched_array (3696, 4560)\n",
      "Time taken including stitching: 12.731143236160278 seconds\n",
      "prediction.clip_tiff, tiff gs://tf_records_bucket/labels/continuous_label_raster.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 13:07:54.338421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-09 13:07:54.338725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3694, 4583, 8)\n",
      "(3694, 4583, 8)\n",
      "(3694, 4583, 1)\n",
      "(3694, 4583, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [462,573,8,8,1] != values[1].shape = [264726,8,8,1] [Op:Pack]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 766\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    752\u001b[0m     input_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://tf_records_bucket/tf_records/Untitled Folder/\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# make sure / is there at the end,\u001b[39;00m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbucket_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_records_bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    764\u001b[0m     }  \u001b[38;5;66;03m# makesure there is a slash at the end of the path  # Choose an appropriate batch size\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 648\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m image_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# img_size = (patch_height, patch_width)\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \n\u001b[1;32m    645\u001b[0m \n\u001b[1;32m    646\u001b[0m \n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# get the train and test datasets\u001b[39;00m\n\u001b[0;32m--> 648\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_tfrecords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_names\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain and Valid datasets are created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# create img_size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 540\u001b[0m, in \u001b[0;36mtrain_test_datasets\u001b[0;34m(input_directory, patch_height, patch_width, image_channels, label_channels, threshold_percentage, batch_size, image_names)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_datasets\u001b[39m(\n\u001b[1;32m    530\u001b[0m     input_directory,\n\u001b[1;32m    531\u001b[0m     patch_height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     image_names\n\u001b[1;32m    538\u001b[0m ):\n\u001b[1;32m    539\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(input_directory, image_names)\n\u001b[0;32m--> 540\u001b[0m     image_patch_tensors_list, label_patch_tensors_list \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(image_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    550\u001b[0m     combined_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(label_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 505\u001b[0m, in \u001b[0;36mparsing\u001b[0;34m(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\u001b[0m\n\u001b[1;32m    502\u001b[0m label_patches \u001b[38;5;241m=\u001b[39m tile_image(label, label_channels, patch_height, patch_width)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# sampling\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m sampled_mask, sampled_tensor \u001b[38;5;241m=\u001b[39m \u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m sampled_image_patches \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(image_patches, sampled_mask)\n\u001b[1;32m    507\u001b[0m sampled_label_patches \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mboolean_mask(label_patches, sampled_mask)\n",
      "Cell \u001b[0;32mIn[1], line 445\u001b[0m, in \u001b[0;36msampling\u001b[0;34m(label_image, threshold_percentage)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msampling\u001b[39m(label_image, threshold_percentage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m99.9\u001b[39m):\n\u001b[1;32m    444\u001b[0m     num_zeros \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(\n\u001b[0;32m--> 445\u001b[0m         tf\u001b[38;5;241m.\u001b[39mcast(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, tf\u001b[38;5;241m.\u001b[39mfloat32), axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Calculate the total number of elements in each patch\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     total_elements \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mreduce_prod(tf\u001b[38;5;241m.\u001b[39mshape(label_image)[\u001b[38;5;241m2\u001b[39m:]), tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pack_N_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [462,573,8,8,1] != values[1].shape = [264726,8,8,1] [Op:Pack]"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install Pillow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n",
    "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "# metrics_results = compute_metrics(new_ground_truth, new_predict)\n",
    "\n",
    "\n",
    "# metrics_results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "class_colors = {\n",
    "        1: ( 5, 5, 230),\n",
    "        2: (190, 60, 15),\n",
    "        3: (65, 240, 125),\n",
    "        4: (105, 200, 95),\n",
    "        5: ( 30, 115, 10),\n",
    "        6: ( 255, 196, 34),\n",
    "        7: (110, 85, 5),\n",
    "        8: ( 235, 235, 220),\n",
    "        9: (120, 216, 47),\n",
    "        10: ( 84, 142, 128),\n",
    "        11: ( 84, 142, 128),\n",
    "        12: ( 84, 142, 128),\n",
    "        13: ( 50, 255, 215),\n",
    "        14: ( 50, 255, 215),\n",
    "        15: ( 50, 255, 215),\n",
    "        16: ( 193, 255, 0),\n",
    "        17: ( 105, 200, 95),\n",
    "        18: (105, 200, 95),\n",
    "        19: ( 105, 200, 95),\n",
    "        20: (193, 255, 0),\n",
    "        21: ( 255, 50, 185),\n",
    "        22: (255, 255, 255),\n",
    "}\n",
    "\n",
    "# Create a colormap using the class-color mapping\n",
    "colors = [class_colors[i] for i in range(1, 23)]\n",
    "normalized_colors_array = np.array([tuple(np.array(v) / 255.0) for v in class_colors.values()])\n",
    "\n",
    "cmap_image = ListedColormap(normalized_colors_array)\n",
    "\n",
    "\n",
    "\n",
    "class CustomMetricsCSVLogger(Callback):\n",
    "    def __init__(self, filename, separator=',', append=True):\n",
    "        super(CustomMetricsCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.append_header = True\n",
    "        self.max_epoch = 0  # Track the highest epoch number encountered\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Initialize min and max class-wise IOU at the beginning of each epoch\n",
    "        self.min_class_wise_iou = 100\n",
    "        self.max_class_wise_iou = 0\n",
    "\n",
    "        # Check if the file exists in Cloud Storage, if not, create it\n",
    "        if not self.file_exists():\n",
    "            self.create_file()\n",
    "\n",
    "    def file_exists(self):\n",
    "        # Check if the file exists in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        return blob.exists()\n",
    "\n",
    "    def create_file(self):\n",
    "        # Create the file in Cloud Storage and write the header\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Write the header to the blob\n",
    "        header = 'epoch,loss,val_loss,class_wise_iou,class_wise_dice_score,class_wise_accuracy,class_wise_precision,class_wise_recall,mean_iou,min_class_wise_iou,max_class_wise_iou\\n'\n",
    "        blob.upload_from_string(header)\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "\n",
    "        # Extract class-wise IOU\n",
    "        class_wise_iou = logs.get('class_wise_iou', 0.0)\n",
    "\n",
    "        # Update min and max class-wise IOU\n",
    "        self.min_class_wise_iou = min(self.min_class_wise_iou, class_wise_iou)\n",
    "        self.max_class_wise_iou = max(self.max_class_wise_iou, class_wise_iou)\n",
    "\n",
    "        # Append the row to the file in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download existing content\n",
    "        existing_content = blob.download_as_text() if blob.exists() else \"\"\n",
    "\n",
    "        # Extract metrics values from logs\n",
    "        metrics_values = [str(logs[key]) for key in ['loss', 'val_loss', 'class_wise_iou', 'class_wise_dice_score',\n",
    "                                                    'class_wise_accuracy', 'class_wise_precision', 'class_wise_recall', 'mean_iou']]\n",
    "\n",
    "        # Check if metrics for the current epoch already exist\n",
    "        epoch_exists = any(f\"{epoch},\" in line for line in existing_content.split('\\n'))\n",
    "\n",
    "        # If the file is empty or epoch entry doesn't exist, append the metrics\n",
    "        if not existing_content or not epoch_exists:\n",
    "            updated_content = existing_content + f\"{epoch},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "        else:\n",
    "            # Get the maximum epoch number in the existing content\n",
    "            max_existing_epoch = max(\n",
    "                int(line.split(',')[0]) for line in existing_content.split('\\n') if line.strip() and not line.startswith('epoch')\n",
    "            )\n",
    "\n",
    "            # Increment the epoch for the new entries\n",
    "            updated_content = existing_content + f\"{max_existing_epoch + 1},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "\n",
    "        # Update the highest epoch number\n",
    "        self.max_epoch = max(self.max_epoch, epoch)\n",
    "\n",
    "        # Upload updated content\n",
    "        blob.upload_from_string(updated_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class PredictSegmentationCallback(Callback):\n",
    "    def __init__(self, test_image_path, output_save_path):\n",
    "        super(PredictSegmentationCallback, self).__init__()\n",
    "        self.test_image_path = test_image_path\n",
    "        self.output_save_path = output_save_path\n",
    "        self.last_predicted_array = None\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     # Call your prediction function\n",
    "    #     self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "    #     normalized_array_image = self.last_predicted_array / (np.max(self.last_predicted_array) + 1e-10)\n",
    "    #     # Display the predicted array with the specified colormap\n",
    "    #     # plt.figure(figsize=(8, 4))\n",
    "    #     # plt.imshow(normalized_array_image, cmap=cmap_image)  # Adjust the colormap as needed\n",
    "    #     # plt.title(f'Predicted Array - Epoch {epoch}')\n",
    "    #     # plt.show()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            # Save the predicted array every 20 epochs\n",
    "            # Convert NumPy array to PIL Image\n",
    "            self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "            pil_image = Image.fromarray((self.last_predicted_array * 255).astype(np.uint8))\n",
    "\n",
    "            # Apply the colormap to the PIL Image\n",
    "            pil_image_colored = pil_image.convert('P', palette=Image.ADAPTIVE, colors=len(class_colors))\n",
    "            pil_image_colored.putpalette(np.array(normalized_colors_array * 255, dtype=np.uint8).flatten())\n",
    "\n",
    "            # Extract image name from the test_image_path for Google Cloud Storage\n",
    "            image_name = os.path.basename(self.test_image_path)\n",
    "\n",
    "            # Create the full GCS path for saving the predicted array as an image\n",
    "            gcs_content_save_path = f'{self.output_save_path}/output_epoch_{epoch}_{image_name}.png'\n",
    "\n",
    "            # Upload the image directly to GCS\n",
    "            storage_client = storage.Client()\n",
    "            bucket_name, blob_name = self.parse_gcs_path(gcs_content_save_path)\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Save the PIL Image to a BytesIO object\n",
    "            image_io = io.BytesIO()\n",
    "            pil_image_colored.save(image_io, format='PNG')\n",
    "\n",
    "            image_io.seek(0)\n",
    "\n",
    "            # Upload the image content to GCS\n",
    "            blob.upload_from_file(image_io, content_type='image/png')  # Set the correct content type\n",
    "\n",
    "            print(f'Predicted array saved at: {gcs_content_save_path}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# imports================\n",
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from pipeline_scripts.model_file import get_model\n",
    "\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    # print(f\"TFRecords List: {tfrecord_files}\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files).map(parse\n",
    "                                                         ) # , num_parallel_reads=tf.data.AUTOTUNE\n",
    "    # dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) \n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "# # pre-processing functions\n",
    "# def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "#     input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "#     min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "#     max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "#     denom = max_val - min_val\n",
    "#     denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "#     normalized_tensor = (input_tensor - min_val) / denom\n",
    "#     return normalized_tensor\n",
    "\n",
    "\n",
    "\n",
    "# def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "#     target_height = tf.cast(tf.math.ceil(tf.shape(image)[0] / TILE_HT) * TILE_HT, tf.int32)\n",
    "#     target_width = tf.cast(tf.math.ceil(tf.shape(image)[1] / TILE_WD) * TILE_WD, tf.int32)\n",
    "#     padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "#     return padded_image\n",
    "\n",
    "\n",
    "\n",
    "# def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "#     fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "#     images = tf.expand_dims(fullimg, axis=0)\n",
    "#     tiles = tf.image.extract_patches(\n",
    "#         images=images,\n",
    "#         sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "#         strides=[1, TILE_HT, TILE_WD, 1],\n",
    "#         rates=[1, 1, 1, 1],\n",
    "#         padding=\"VALID\",\n",
    "#     )\n",
    "\n",
    "#     tiles = tf.squeeze(tiles, axis=0)\n",
    "#     nrows = tiles.shape[0]\n",
    "#     ncols = tiles.shape[1]\n",
    "#     tiles = tf.reshape(tiles, [nrows, ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "#     return tiles\n",
    "\n",
    "\n",
    "# def sampling(label_image, threshold_percentage=99.9):\n",
    "#     num_zeros = tf.reduce_sum(\n",
    "#         tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "#     )\n",
    "#     total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "#     percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "#     boolean_mask = percentage_zeros <= threshold_percentage\n",
    "#     sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "#     return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "\n",
    "# def one_hot_encoding(label_tensor):\n",
    "#     float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "#     num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "#     one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "#     return one_hot_encoded_images\n",
    "\n",
    "\n",
    "# # Optimized parsing function using tf.data.Dataset\n",
    "# def parsing(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "#     def parse_example(parsed_example):\n",
    "#         image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "#         # print(\"parsed_example\", parsed_example)\n",
    "#         # print('parsed_example[\"image_shape\"]', parsed_example[\"image_shape\"])\n",
    "#         # print(\"image shape in parse example\", image_shape)\n",
    "#         image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "#         label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "#         label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "        \n",
    "#         image = bandwise_normalize(image)\n",
    "#         print(f\"Bandwise Norm Image Shape: {image.shape}\")\n",
    "#         image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "#         label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "        \n",
    "#         sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "#         sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "#         sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "        \n",
    "#         sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "        \n",
    "#         return sampled_image_patches, sampled_label_patches\n",
    "    \n",
    "#     image_patch_tensors_list = []\n",
    "#     label_patch_tensors_list = []\n",
    "#     for parsed_data in dataset:\n",
    "#         sampled_image_patches, sampled_label_patches = parse_example(parsed_data)\n",
    "#         image_patch_tensors_list.append(sampled_image_patches)\n",
    "#         label_patch_tensors_list.append(sampled_label_patches)\n",
    "#     return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    # Convert the input_tensor to a float32 type\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "\n",
    "    # Calculate the minimum and maximum values along the channel axis\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "\n",
    "    # Check for potential numerical instability\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "\n",
    "    # Normalize the tensor band-wise to the range [0, 1]\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "\n",
    "    return normalized_tensor\n",
    "\n",
    "\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    # Get the current dimensions\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Calculate the target dimensions\n",
    "    target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "\n",
    "    # Calculate the amount of padding\n",
    "    pad_height = target_height - height\n",
    "    pad_width = target_width - width\n",
    "\n",
    "    # Pad the image\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    nrows = tiles.shape[0]\n",
    "    ncols = tiles.shape[1]\n",
    "    tiles = tf.reshape(tiles, [nrows, ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(\n",
    "        tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "    )\n",
    "\n",
    "    # Calculate the total number of elements in each patch\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "\n",
    "    # Calculate the percentage of zeros in each patch\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    # Apply the threshold logic\n",
    "    sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "    return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "def one_hot_encoding(label_tensor):\n",
    "    # Assuming your pixel values are float labels\n",
    "    float_labels = tf.squeeze(\n",
    "        label_tensor, axis=-1\n",
    "    )  # Assuming channel dimension is the last one\n",
    "\n",
    "    # Determine the number of classes dynamically\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "\n",
    "    # One-hot encode each image\n",
    "    one_hot_encoded_images = tf.one_hot(\n",
    "        tf.dtypes.cast(float_labels, tf.int32), depth=num_classes\n",
    "    )\n",
    "\n",
    "    # Print the shape of the resulting tensor and the number of classes\n",
    "    # print(\"Shape of one-hot encoded images:\", one_hot_encoded_images.shape)\n",
    "    # print(\"Number of classes:\", num_classes)\n",
    "\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "def parsing(\n",
    "    dataset,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    threshold_percentage,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "):\n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "\n",
    "    for parsed_example in dataset:\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "\n",
    "        # image normalization\n",
    "        image = bandwise_normalize(image)\n",
    "\n",
    "        # image and label patching\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "        # sampling\n",
    "        sampled_mask, sampled_tensor = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "        # one-hot encoding\n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "        # save them in the list\n",
    "        image_patch_tensors_list.append(sampled_image_patches)\n",
    "        label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    image_names\n",
    "):\n",
    "    dataset = create_dataset(input_directory, image_names)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "    \n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "    \n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "config = load_config('./pipeline_scripts/config.json')\n",
    "from google.cloud import storage\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.python.lib.io import file_io\n",
    "# Convert img_size to a tuple\n",
    "config[\"img_size\"] = tuple(config[\"img_size\"])\n",
    "\n",
    "# Now you can access the config values normally\n",
    "model_path = config.get(\"model_path\")\n",
    "model_name = config.get(\"model_name\")\n",
    "test_image_path = config.get(\"test_image_path\")\n",
    "img_size = config.get(\"img_size\")\n",
    "num_bands = config.get(\"num_bands\")\n",
    "num_classes = config.get(\"num_classes\")\n",
    "gcs_path = config.get(\"google_storage_path\")\n",
    "gcs_tfrecords = config.get(\"gcs_tfrecords\")\n",
    "\n",
    "\n",
    "# Load the model if a checkpoint exists\n",
    "# Load the model if a checkpoint exists\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='gislogics')  # Set up GCS connection\n",
    "\n",
    "if tf.io.gfile.exists(model_path):  # Accurately check for file existence in GCS\n",
    "    # Load existing model\n",
    "    model = load_model(model_path)  # Handle GCS authentication here if needed\n",
    "    print(\"Loaded model from checkpoint\")\n",
    "else:\n",
    "    # If no checkpoint exists, create a new model\n",
    "    model = get_model(\n",
    "        img_size=img_size, num_classes=num_classes, num_bands=num_bands\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    print(\"Created a new model\")\n",
    "\n",
    "    # # Save the new model to the model_path in GCS\n",
    "    save_model(model, model_path)\n",
    "    print(\"Saved new model to:\", model_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Continue training\n",
    "from pipeline_scripts.eval import *\n",
    "from pipeline_scripts.prediction import *\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")  \n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "\n",
    "    image_names = kwargs.get(\"image_names\")\n",
    "    # img_size = (patch_height, patch_width)\n",
    "    \n",
    "    \n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        gcs_tfrecords,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "    # create img_size\n",
    "    model = get_model(\n",
    "        img_size= img_size, \n",
    "        num_classes=num_classes, \n",
    "        num_bands=image_channels\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # compilation of model, with custom metric\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=[np.mean(compute_metrics(new_ground_truth, new_predict)[0])]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Early stopping after 5 epochs \n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,  \n",
    "    restore_best_weights=True,  \n",
    "    verbose=1  \n",
    "    )\n",
    "    \n",
    "    # Agroforestry Class\n",
    "    Agroforestry = 18\n",
    "    \n",
    "    # including custom metrics in callbacks\n",
    "    custom_metrics_callback = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logs.update({\n",
    "        \"class_wise_iou\": compute_metrics(new_ground_truth, new_predict)[0][Agroforestry],\n",
    "        \"class_wise_dice_score\": compute_metrics(new_ground_truth, new_predict)[1][Agroforestry],\n",
    "        \"class_wise_accuracy\": compute_metrics(new_ground_truth, new_predict)[2][Agroforestry],\n",
    "        \"class_wise_precision\": compute_metrics(new_ground_truth, new_predict)[3][Agroforestry],\n",
    "        \"class_wise_recall\": compute_metrics(new_ground_truth, new_predict)[4][Agroforestry],\n",
    "        \"mean_iou\": compute_metrics(new_ground_truth, new_predict)[5],\n",
    "        \"min_class_wise_iou\": np.min(metrics_results[0]),\n",
    "        \"max_class_wise_iou\": np.max(metrics_results[0]),\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": logs[\"loss\"],\n",
    "        \"val_loss\": logs[\"val_loss\"]}))\n",
    "\n",
    "    \n",
    "    # callbacks and logging\n",
    "    csv_logger = keras.callbacks.CSVLogger(\n",
    "    input_directory + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "    append=True\n",
    "    )\n",
    "\n",
    "    custom_metrics_csv_logger = CustomMetricsCSVLogger(\n",
    "        input_params[\"input_directory\"] + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "        append=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"gs://tf_records_bucket/tf_records/Untitled Folder/logs/\"  # Specify the directory to save logs\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    output_of_image = \"gs://tf_records_bucket/tf_records/Untitled Folder/output\"\n",
    "    \n",
    "    # Combine all callbacks\n",
    "    all_callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(model_path + model_name, save_best_only=False),\n",
    "        tensorboard_callback,\n",
    "        custom_metrics_callback,\n",
    "        custom_metrics_csv_logger,  # Add the custom_metrics_csv_logger here\n",
    "        # early_stopping,\n",
    "        PredictSegmentationCallback(test_image_path, output_of_image)\n",
    "    ]\n",
    "\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=3,\n",
    "        callbacks=all_callbacks,\n",
    "        batch_size=32,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped at epoch {early_stopping.stopped_epoch} due to early stopping.\")\n",
    "    else:\n",
    "        print(\"Training completed all epochs.\")\n",
    "    # Save the model after training\n",
    "    # model.save(model_path + model_name)\n",
    "    # print(\"Model saved locally\")\n",
    "\n",
    "    upload_blob(gcs_path)\n",
    "    print(\"Uploaded to cloud storage successfully\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_names\" : [],\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a12c0d-7966-4367-ad27-386705a2ba34",
   "metadata": {},
   "source": [
    "## Testing on only train part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6172f1ba-5e61-4ae2-a4b2-7814da740fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 16:38:11.647764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-09 16:38:12.276841: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1780] (One-time warning): Not using XLA:CPU for cluster.\n",
      "\n",
      "If you want XLA:CPU, do one of the following:\n",
      "\n",
      " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
      " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
      " - use experimental_jit_scope, or\n",
      " - use tf.function(jit_compile=True).\n",
      "\n",
      "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
      "proper command-line flag, not via TF_XLA_FLAGS).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Valid datasets are created\n"
     ]
    }
   ],
   "source": [
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from pipeline_scripts.model_file import get_model\n",
    "import json\n",
    "from datetime import datetime\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(parse)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# # pre-processing functions\n",
    "# def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "#     # Convert the input_tensor to a float32 type\n",
    "#     input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "\n",
    "#     # Calculate the minimum and maximum values along the channel axis\n",
    "#     min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "#     max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "\n",
    "#     # Check for potential numerical instability\n",
    "#     denom = max_val - min_val\n",
    "#     denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "\n",
    "#     # Normalize the tensor band-wise to the range [0, 1]\n",
    "#     normalized_tensor = (input_tensor - min_val) / denom\n",
    "\n",
    "#     return normalized_tensor\n",
    "\n",
    "\n",
    "# def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "#     # Get the current dimensions\n",
    "#     height, width, channels = image.shape\n",
    "\n",
    "#     # Calculate the target dimensions\n",
    "#     target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "#     target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "\n",
    "#     # Calculate the amount of padding\n",
    "#     pad_height = target_height - height\n",
    "#     pad_width = target_width - width\n",
    "\n",
    "#     # Pad the image\n",
    "#     padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "\n",
    "#     return padded_image\n",
    "\n",
    "\n",
    "# def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "#     fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "#     images = tf.expand_dims(fullimg, axis=0)\n",
    "#     tiles = tf.image.extract_patches(\n",
    "#         images=images,\n",
    "#         sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "#         strides=[1, TILE_HT, TILE_WD, 1],\n",
    "#         rates=[1, 1, 1, 1],\n",
    "#         padding=\"VALID\",\n",
    "#     )\n",
    "\n",
    "#     tiles = tf.squeeze(tiles, axis=0)\n",
    "#     nrows = tiles.shape[0]\n",
    "#     ncols = tiles.shape[1]\n",
    "#     tiles = tf.reshape(tiles, [nrows, ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "#     return tiles\n",
    "\n",
    "\n",
    "# def sampling(label_image, threshold_percentage=99.9):\n",
    "#     num_zeros = tf.reduce_sum(\n",
    "#         tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "#     )\n",
    "\n",
    "#     # Calculate the total number of elements in each patch\n",
    "#     total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "\n",
    "#     # Calculate the percentage of zeros in each patch\n",
    "#     percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "\n",
    "#     boolean_mask = percentage_zeros <= threshold_percentage\n",
    "#     # Apply the threshold logic\n",
    "#     sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "#     return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "# def one_hot_encoding(label_tensor):\n",
    "#     # Assuming your pixel values are float labels\n",
    "#     float_labels = tf.squeeze(\n",
    "#         label_tensor, axis=-1\n",
    "#     )  # Assuming channel dimension is the last one\n",
    "\n",
    "#     # Determine the number of classes dynamically\n",
    "#     num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "\n",
    "#     # One-hot encode each image\n",
    "#     one_hot_encoded_images = tf.one_hot(\n",
    "#         tf.dtypes.cast(float_labels, tf.int32), depth=num_classes\n",
    "#     )\n",
    "\n",
    "#     # Print the shape of the resulting tensor and the number of classes\n",
    "#     # print(\"Shape of one-hot encoded images:\", one_hot_encoded_images.shape)\n",
    "#     # print(\"Number of classes:\", num_classes)\n",
    "\n",
    "#     return one_hot_encoded_images\n",
    "\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "    return normalized_tensor\n",
    "\n",
    "\n",
    "\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    target_height = tf.cast(tf.math.ceil(tf.shape(image)[0] / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(tf.shape(image)[1] / TILE_WD) * TILE_WD, tf.int32)\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    tiles = tf.cast(tiles, tf.float32)\n",
    "    tiles = tf.reshape(tiles, [tf.shape(tiles)[0], tf.shape(tiles)[1], TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(\n",
    "        tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "    )\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "    return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encoding(label_tensor):\n",
    "    float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "    one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "\n",
    "\n",
    "def parsing(\n",
    "    dataset,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    threshold_percentage,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "):\n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "    \n",
    "    \n",
    "    def _parse(parsed_example):\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "        \n",
    "        # Assuming image_channels is known and fixed\n",
    "        # image.set_shape([None, None, image_channels])\n",
    "        # label.set_shape([None, None, 1])\n",
    "        \n",
    "        # image normalization\n",
    "        image = bandwise_normalize(image)\n",
    "\n",
    "        # image and label patching\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "        # sampling\n",
    "        sampled_mask, sampled_tensor = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "        # one-hot encoding\n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "        return sampled_image_patches, sampled_label_patches\n",
    "    \n",
    "    parsed_dataset = dataset.map(lambda x: _parse(x))\n",
    "    for sampled_image_patches, sampled_label_patches in parsed_dataset:\n",
    "        image_patch_tensors_list.append(sampled_image_patches)\n",
    "        label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    image_names\n",
    "):\n",
    "    dataset = create_dataset(input_directory, image_names)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "\n",
    "    # Combine images and labels from different pairs\n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")\n",
    "    # model_path = config.get(\"model_path\")\n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "    img_size = (patch_height, patch_width)\n",
    "    # model_name = config.get(\"model_name\")\n",
    "    image_names = kwargs.get(\"image_names\")\n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        input_directory,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"image_names\": [],\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        # \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac18ddb-9701-45ff-97dc-af6deb63e39d",
   "metadata": {},
   "source": [
    "## Testing on whole codebase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78afc60f-189d-4bff-abdc-03e2a29f1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2023.11.17)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.23.5)\n",
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Using cached snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from rasterio) (68.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
      "Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Using cached snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.9 snuggs-1.4.7\n",
      "Collecting geopandas\n",
      "  Using cached geopandas-0.14.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas)\n",
      "  Using cached fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.3)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Using cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.23.5)\n",
      "Using cached geopandas-0.14.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl (15.7 MB)\n",
      "Using cached pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Installing collected packages: pyproj, fiona, geopandas\n",
      "Successfully installed fiona-1.9.6 geopandas-0.14.3 pyproj-3.6.1\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 22:59:54.464931: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 23:00:08.672702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint\n",
      "prediction.clip_tiff, tiff gs://tf_records_bucket/labels/area2_0530_2022_8bands.tif\n",
      "(3694, 4560, 8)\n",
      "(3694, 4560, 8)\n",
      "dims (3696, 4560, 8)\n",
      "129/129 [==============================] - 11s 76ms/step\n",
      "Time taken for predictions: 12.892645597457886 seconds\n",
      "segmentation_patches_reshaped.shape (462, 570, 8, 8)\n",
      "row_indices_patch (462,)\n",
      "col_indices_patch (570,)\n",
      "stitched_array (3696, 4560)\n",
      "Time taken including stitching: 14.933786630630493 seconds\n",
      "prediction.clip_tiff, tiff gs://tf_records_bucket/labels/continuous_label_raster.tif\n",
      "<unknown>\n",
      "<unknown>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_1/3823001887.py\", line 420, in None  *\n        lambda x: _parse(x)\n    File \"/tmp/ipykernel_1/3823001887.py\", line 407, in _parse  *\n        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 135, in tile_image  *\n        fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 117, in pad_to_multiple  *\n        height, width, channels = image.shape\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 675\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    661\u001b[0m     input_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://tf_records_bucket/tf_records/Untitled Folder/\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# make sure / is there at the end,\u001b[39;00m\n\u001b[1;32m    663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbucket_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_records_bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m     }  \u001b[38;5;66;03m# makesure there is a slash at the end of the path  # Choose an appropriate batch size\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 557\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m image_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# img_size = (patch_height, patch_width)\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \n\u001b[1;32m    554\u001b[0m \n\u001b[1;32m    555\u001b[0m \n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# get the train and test datasets\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_tfrecords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_names\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain and Valid datasets are created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# create img_size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 449\u001b[0m, in \u001b[0;36mtrain_test_datasets\u001b[0;34m(input_directory, patch_height, patch_width, image_channels, label_channels, threshold_percentage, batch_size, image_names)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_datasets\u001b[39m(\n\u001b[1;32m    439\u001b[0m     input_directory,\n\u001b[1;32m    440\u001b[0m     patch_height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    446\u001b[0m     image_names\n\u001b[1;32m    447\u001b[0m ):\n\u001b[1;32m    448\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(input_directory, image_names)\n\u001b[0;32m--> 449\u001b[0m     image_patch_tensors_list, label_patch_tensors_list \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(image_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    459\u001b[0m     combined_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(label_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 420\u001b[0m, in \u001b[0;36mparsing\u001b[0;34m(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\u001b[0m\n\u001b[1;32m    416\u001b[0m     sampled_label_patches \u001b[38;5;241m=\u001b[39m one_hot_encoding(sampled_label_patches)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampled_image_patches, sampled_label_patches\n\u001b[0;32m--> 420\u001b[0m parsed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sampled_image_patches, sampled_label_patches \u001b[38;5;129;01min\u001b[39;00m parsed_dataset:\n\u001b[1;32m    422\u001b[0m     image_patch_tensors_list\u001b[38;5;241m.\u001b[39mappend(sampled_image_patches)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    233\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    235\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    168\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 169\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileveqhxryt.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 6\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlscope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/core/function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[0;34m(thunk, scope_name, options)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileveqhxryt.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[0;34m(lscope)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[0;32m----> 6\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileq935ko2w.py:20\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___parse\u001b[0;34m(parsed_example)\u001b[0m\n\u001b[1;32m     18\u001b[0m label \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mto_dense, (ag__\u001b[38;5;241m.\u001b[39mld(parsed_example)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(label_shape)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(bandwise_normalize), (ag__\u001b[38;5;241m.\u001b[39mld(image),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 20\u001b[0m image_patches \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m label_patches \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tile_image), (ag__\u001b[38;5;241m.\u001b[39mld(label), ag__\u001b[38;5;241m.\u001b[39mld(label_channels), ag__\u001b[38;5;241m.\u001b[39mld(patch_height), ag__\u001b[38;5;241m.\u001b[39mld(patch_width)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     22\u001b[0m (sampled_mask, sampled_tensor) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(sampling), (ag__\u001b[38;5;241m.\u001b[39mld(label_patches), ag__\u001b[38;5;241m.\u001b[39mld(threshold_percentage)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filec8f8fsgf.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tile_image\u001b[0;34m(fullimg, CHANNELS, TILE_HT, TILE_WD)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(fullimg)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m fullimg \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_to_multiple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTILE_HT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTILE_WD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m images \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(fullimg),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[1;32m     13\u001b[0m tiles \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mextract_patches, (), \u001b[38;5;28mdict\u001b[39m(images\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(images), sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), \u001b[38;5;241m1\u001b[39m], strides\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), \u001b[38;5;241m1\u001b[39m], rates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileghm1pz3a.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__pad_to_multiple\u001b[0;34m(image, TILE_HT, TILE_WD)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(image)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m (height, width, channels) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(image)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     12\u001b[0m target_height \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil, (ag__\u001b[38;5;241m.\u001b[39mld(height) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_HT), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m target_width \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil, (ag__\u001b[38;5;241m.\u001b[39mld(width) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(TILE_WD), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:929\u001b[0m, in \u001b[0;36mTensorShape.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns `self.dims` if the rank is known, otherwise raises ValueError.\"\"\"\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a shape with unknown rank.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_1/3823001887.py\", line 420, in None  *\n        lambda x: _parse(x)\n    File \"/tmp/ipykernel_1/3823001887.py\", line 407, in _parse  *\n        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 135, in tile_image  *\n        fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n    File \"/home/jupyter/eval_and_pred/pipeline_scripts/prediction.py\", line 117, in pad_to_multiple  *\n        height, width, channels = image.shape\n\n    ValueError: Cannot iterate over a shape with unknown rank.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install Pillow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n",
    "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "# metrics_results = compute_metrics(new_ground_truth, new_predict)\n",
    "\n",
    "\n",
    "# metrics_results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "class_colors = {\n",
    "        1: ( 5, 5, 230),\n",
    "        2: (190, 60, 15),\n",
    "        3: (65, 240, 125),\n",
    "        4: (105, 200, 95),\n",
    "        5: ( 30, 115, 10),\n",
    "        6: ( 255, 196, 34),\n",
    "        7: (110, 85, 5),\n",
    "        8: ( 235, 235, 220),\n",
    "        9: (120, 216, 47),\n",
    "        10: ( 84, 142, 128),\n",
    "        11: ( 84, 142, 128),\n",
    "        12: ( 84, 142, 128),\n",
    "        13: ( 50, 255, 215),\n",
    "        14: ( 50, 255, 215),\n",
    "        15: ( 50, 255, 215),\n",
    "        16: ( 193, 255, 0),\n",
    "        17: ( 105, 200, 95),\n",
    "        18: (105, 200, 95),\n",
    "        19: ( 105, 200, 95),\n",
    "        20: (193, 255, 0),\n",
    "        21: ( 255, 50, 185),\n",
    "        22: (255, 255, 255),\n",
    "}\n",
    "\n",
    "# Create a colormap using the class-color mapping\n",
    "colors = [class_colors[i] for i in range(1, 23)]\n",
    "normalized_colors_array = np.array([tuple(np.array(v) / 255.0) for v in class_colors.values()])\n",
    "\n",
    "cmap_image = ListedColormap(normalized_colors_array)\n",
    "\n",
    "\n",
    "\n",
    "class CustomMetricsCSVLogger(Callback):\n",
    "    def __init__(self, filename, separator=',', append=True):\n",
    "        super(CustomMetricsCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.separator = separator\n",
    "        self.append = append\n",
    "        self.keys = None\n",
    "        self.append_header = True\n",
    "        self.max_epoch = 0  # Track the highest epoch number encountered\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Initialize min and max class-wise IOU at the beginning of each epoch\n",
    "        self.min_class_wise_iou = 100\n",
    "        self.max_class_wise_iou = 0\n",
    "\n",
    "        # Check if the file exists in Cloud Storage, if not, create it\n",
    "        if not self.file_exists():\n",
    "            self.create_file()\n",
    "\n",
    "    def file_exists(self):\n",
    "        # Check if the file exists in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        return blob.exists()\n",
    "\n",
    "    def create_file(self):\n",
    "        # Create the file in Cloud Storage and write the header\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Write the header to the blob\n",
    "        header = 'epoch,loss,val_loss,class_wise_iou,class_wise_dice_score,class_wise_accuracy,class_wise_precision,class_wise_recall,mean_iou,min_class_wise_iou,max_class_wise_iou\\n'\n",
    "        blob.upload_from_string(header)\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if self.keys is None:\n",
    "            self.keys = sorted(logs.keys())\n",
    "\n",
    "        # Extract class-wise IOU\n",
    "        class_wise_iou = logs.get('class_wise_iou', 0.0)\n",
    "\n",
    "        # Update min and max class-wise IOU\n",
    "        self.min_class_wise_iou = min(self.min_class_wise_iou, class_wise_iou)\n",
    "        self.max_class_wise_iou = max(self.max_class_wise_iou, class_wise_iou)\n",
    "\n",
    "        # Append the row to the file in Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "        bucket_name, blob_name = self.parse_gcs_path(self.filename)\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download existing content\n",
    "        existing_content = blob.download_as_text() if blob.exists() else \"\"\n",
    "\n",
    "        # Extract metrics values from logs\n",
    "        metrics_values = [str(logs[key]) for key in ['loss', 'val_loss', 'class_wise_iou', 'class_wise_dice_score',\n",
    "                                                    'class_wise_accuracy', 'class_wise_precision', 'class_wise_recall', 'mean_iou']]\n",
    "\n",
    "        # Check if metrics for the current epoch already exist\n",
    "        epoch_exists = any(f\"{epoch},\" in line for line in existing_content.split('\\n'))\n",
    "\n",
    "        # If the file is empty or epoch entry doesn't exist, append the metrics\n",
    "        if not existing_content or not epoch_exists:\n",
    "            updated_content = existing_content + f\"{epoch},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "        else:\n",
    "            # Get the maximum epoch number in the existing content\n",
    "            max_existing_epoch = max(\n",
    "                int(line.split(',')[0]) for line in existing_content.split('\\n') if line.strip() and not line.startswith('epoch')\n",
    "            )\n",
    "\n",
    "            # Increment the epoch for the new entries\n",
    "            updated_content = existing_content + f\"{max_existing_epoch + 1},{','.join(metrics_values)},{self.min_class_wise_iou},{self.max_class_wise_iou}\\n\"\n",
    "\n",
    "        # Update the highest epoch number\n",
    "        self.max_epoch = max(self.max_epoch, epoch)\n",
    "\n",
    "        # Upload updated content\n",
    "        blob.upload_from_string(updated_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class PredictSegmentationCallback(Callback):\n",
    "    def __init__(self, test_image_path, output_save_path):\n",
    "        super(PredictSegmentationCallback, self).__init__()\n",
    "        self.test_image_path = test_image_path\n",
    "        self.output_save_path = output_save_path\n",
    "        self.last_predicted_array = None\n",
    "\n",
    "    def parse_gcs_path(self, gcs_path):\n",
    "        # Parse the Google Cloud Storage path to extract bucket name and blob name\n",
    "        parts = gcs_path.replace('gs://', '').split('/')\n",
    "        return parts[0], '/'.join(parts[1:])\n",
    "\n",
    "    # def on_epoch_end(self, epoch, logs=None):\n",
    "    #     # Call your prediction function\n",
    "    #     self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "    #     normalized_array_image = self.last_predicted_array / (np.max(self.last_predicted_array) + 1e-10)\n",
    "    #     # Display the predicted array with the specified colormap\n",
    "    #     # plt.figure(figsize=(8, 4))\n",
    "    #     # plt.imshow(normalized_array_image, cmap=cmap_image)  # Adjust the colormap as needed\n",
    "    #     # plt.title(f'Predicted Array - Epoch {epoch}')\n",
    "    #     # plt.show()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            # Save the predicted array every 20 epochs\n",
    "            # Convert NumPy array to PIL Image\n",
    "            self.last_predicted_array = prediction_function_img(self.test_image_path)\n",
    "            pil_image = Image.fromarray((self.last_predicted_array * 255).astype(np.uint8))\n",
    "\n",
    "            # Apply the colormap to the PIL Image\n",
    "            pil_image_colored = pil_image.convert('P', palette=Image.ADAPTIVE, colors=len(class_colors))\n",
    "            pil_image_colored.putpalette(np.array(normalized_colors_array * 255, dtype=np.uint8).flatten())\n",
    "\n",
    "            # Extract image name from the test_image_path for Google Cloud Storage\n",
    "            image_name = os.path.basename(self.test_image_path)\n",
    "\n",
    "            # Create the full GCS path for saving the predicted array as an image\n",
    "            gcs_content_save_path = f'{self.output_save_path}/output_epoch_{epoch}_{image_name}.png'\n",
    "\n",
    "            # Upload the image directly to GCS\n",
    "            storage_client = storage.Client()\n",
    "            bucket_name, blob_name = self.parse_gcs_path(gcs_content_save_path)\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Save the PIL Image to a BytesIO object\n",
    "            image_io = io.BytesIO()\n",
    "            pil_image_colored.save(image_io, format='PNG')\n",
    "\n",
    "            image_io.seek(0)\n",
    "\n",
    "            # Upload the image content to GCS\n",
    "            blob.upload_from_file(image_io, content_type='image/png')  # Set the correct content type\n",
    "\n",
    "            print(f'Predicted array saved at: {gcs_content_save_path}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# imports================\n",
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from pipeline_scripts.model_file import get_model\n",
    "\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory, image_names=[]):\n",
    "    if len(image_names)==0:\n",
    "        tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    else:\n",
    "        names = [name.split(\".\")[0]+\"_tfrecord\" for name in image_names]\n",
    "        print(names)\n",
    "        tfrecord_files = [\n",
    "            f\"{input_directory}{file}\"\n",
    "            for file in tf.io.gfile.listdir(input_directory)\n",
    "            if file.endswith(\".tfrecord\") and os.path.basename(file).rsplit('.', 1)[0] in names\n",
    "        ]\n",
    "    # print(f\"TFRecords List: {tfrecord_files}\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files).map(parse\n",
    "                                                         ) # , num_parallel_reads=tf.data.AUTOTUNE\n",
    "    # dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "    return normalized_tensor\n",
    "\n",
    "\n",
    "\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    print(f\"Pad2Multiple's Starting Shape: {tf.shape(image)}\")\n",
    "    # shape = tf.shape(image)\n",
    "    # height, width = shape[0], shape[1]\n",
    "    # target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "    # target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "    # padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    \n",
    "    # Obtain the dynamic shape of the image\n",
    "    shape = tf.shape(image)\n",
    "    height, width = shape[0], shape[1]\n",
    "    \n",
    "    # Calculate the padding needed to make the height and width a multiple of TILE_HT and TILE_WD\n",
    "    pad_height = tf.math.floormod(-height, TILE_HT)\n",
    "    pad_width = tf.math.floormod(-width, TILE_WD)\n",
    "    \n",
    "    # Calculate padding for top/bottom and left/right\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    # Create the paddings tensor\n",
    "    paddings = tf.constant([[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]])\n",
    "    \n",
    "    # Pad the image\n",
    "    padded_image = tf.pad(image, paddings, mode=\"CONSTANT\", constant_values=0)\n",
    "    \n",
    "    print(f\"Pad2Multiple's padded Shape: {tf.shape(padded_image)}\")\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    tiles = tf.cast(tiles, tf.float32)\n",
    "    tiles = tf.reshape(tiles, [tf.shape(tiles)[0], tf.shape(tiles)[1], TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(\n",
    "        tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "    )\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "    return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encoding(label_tensor):\n",
    "    float_labels = tf.squeeze(label_tensor, axis=-1)\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "    one_hot_encoded_images = tf.one_hot(tf.dtypes.cast(float_labels, tf.int32), depth=num_classes)\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "\n",
    "\n",
    "def parsing(\n",
    "    dataset,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    threshold_percentage,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "):\n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "    \n",
    "    \n",
    "    def _parse(parsed_example):\n",
    "        image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "        label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "        label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "        \n",
    "        # Assuming image_channels is known and fixed\n",
    "        # image.set_shape([None, None, image_channels])\n",
    "        # label.set_shape([None, None, 1])\n",
    "        \n",
    "        # image normalization\n",
    "        image = bandwise_normalize(image)\n",
    "\n",
    "        # image and label patching\n",
    "        image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "        label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "        # sampling\n",
    "        sampled_mask, sampled_tensor = sampling(label_patches, threshold_percentage)\n",
    "        sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "        sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "        # one-hot encoding\n",
    "        sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "        return sampled_image_patches, sampled_label_patches\n",
    "    \n",
    "    parsed_dataset = dataset.map(lambda x: _parse(x))\n",
    "    for sampled_image_patches, sampled_label_patches in parsed_dataset:\n",
    "        image_patch_tensors_list.append(sampled_image_patches)\n",
    "        label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    image_names\n",
    "):\n",
    "    dataset = create_dataset(input_directory, image_names)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "    \n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "    \n",
    "\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "config = load_config('./pipeline_scripts/config.json')\n",
    "from google.cloud import storage\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.python.lib.io import file_io\n",
    "# Convert img_size to a tuple\n",
    "config[\"img_size\"] = tuple(config[\"img_size\"])\n",
    "\n",
    "# Now you can access the config values normally\n",
    "model_path = config.get(\"model_path\")\n",
    "model_name = config.get(\"model_name\")\n",
    "test_image_path = config.get(\"test_image_path\")\n",
    "img_size = config.get(\"img_size\")\n",
    "num_bands = config.get(\"num_bands\")\n",
    "num_classes = config.get(\"num_classes\")\n",
    "gcs_path = config.get(\"google_storage_path\")\n",
    "gcs_tfrecords = config.get(\"gcs_tfrecords\")\n",
    "\n",
    "\n",
    "# Load the model if a checkpoint exists\n",
    "# Load the model if a checkpoint exists\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='gislogics')  # Set up GCS connection\n",
    "\n",
    "if tf.io.gfile.exists(model_path):  # Accurately check for file existence in GCS\n",
    "    # Load existing model\n",
    "    model = load_model(model_path)  # Handle GCS authentication here if needed\n",
    "    print(\"Loaded model from checkpoint\")\n",
    "else:\n",
    "    # If no checkpoint exists, create a new model\n",
    "    model = get_model(\n",
    "        img_size=img_size, num_classes=num_classes, num_bands=num_bands\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    print(\"Created a new model\")\n",
    "\n",
    "    # # Save the new model to the model_path in GCS\n",
    "    save_model(model, model_path)\n",
    "    print(\"Saved new model to:\", model_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Continue training\n",
    "from pipeline_scripts.eval import *\n",
    "from pipeline_scripts.prediction import *\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")  \n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "\n",
    "    image_names = kwargs.get(\"image_names\")\n",
    "    # img_size = (patch_height, patch_width)\n",
    "    \n",
    "    \n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        gcs_tfrecords,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "    # create img_size\n",
    "    model = get_model(\n",
    "        img_size= img_size, \n",
    "        num_classes=num_classes, \n",
    "        num_bands=image_channels\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # compilation of model, with custom metric\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=[np.mean(compute_metrics(new_ground_truth, new_predict)[0])]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Early stopping after 5 epochs \n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,  \n",
    "    restore_best_weights=True,  \n",
    "    verbose=1  \n",
    "    )\n",
    "    \n",
    "    # Agroforestry Class\n",
    "    Agroforestry = 18\n",
    "    \n",
    "    # including custom metrics in callbacks\n",
    "    custom_metrics_callback = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logs.update({\n",
    "        \"class_wise_iou\": compute_metrics(new_ground_truth, new_predict)[0][Agroforestry],\n",
    "        \"class_wise_dice_score\": compute_metrics(new_ground_truth, new_predict)[1][Agroforestry],\n",
    "        \"class_wise_accuracy\": compute_metrics(new_ground_truth, new_predict)[2][Agroforestry],\n",
    "        \"class_wise_precision\": compute_metrics(new_ground_truth, new_predict)[3][Agroforestry],\n",
    "        \"class_wise_recall\": compute_metrics(new_ground_truth, new_predict)[4][Agroforestry],\n",
    "        \"mean_iou\": compute_metrics(new_ground_truth, new_predict)[5],\n",
    "        \"min_class_wise_iou\": np.min(metrics_results[0]),\n",
    "        \"max_class_wise_iou\": np.max(metrics_results[0]),\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": logs[\"loss\"],\n",
    "        \"val_loss\": logs[\"val_loss\"]}))\n",
    "\n",
    "    \n",
    "    # callbacks and logging\n",
    "    csv_logger = keras.callbacks.CSVLogger(\n",
    "    input_directory + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "    append=True\n",
    "    )\n",
    "\n",
    "    custom_metrics_csv_logger = CustomMetricsCSVLogger(\n",
    "        input_params[\"input_directory\"] + \"logs/\" + f\"training_logs_{model_name}.csv\",\n",
    "        append=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    log_dir = \"gs://tf_records_bucket/tf_records/Untitled Folder/logs/\"  # Specify the directory to save logs\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    output_of_image = \"gs://tf_records_bucket/tf_records/Untitled Folder/output\"\n",
    "    \n",
    "    # Combine all callbacks\n",
    "    all_callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(model_path + model_name, save_best_only=False),\n",
    "        tensorboard_callback,\n",
    "        custom_metrics_callback,\n",
    "        custom_metrics_csv_logger,  # Add the custom_metrics_csv_logger here\n",
    "        # early_stopping,\n",
    "        PredictSegmentationCallback(test_image_path, output_of_image)\n",
    "    ]\n",
    "\n",
    "    model_history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=3,\n",
    "        callbacks=all_callbacks,\n",
    "        batch_size=32,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped at epoch {early_stopping.stopped_epoch} due to early stopping.\")\n",
    "    else:\n",
    "        print(\"Training completed all epochs.\")\n",
    "    # Save the model after training\n",
    "    # model.save(model_path + model_name)\n",
    "    # print(\"Model saved locally\")\n",
    "\n",
    "    upload_blob(gcs_path)\n",
    "    print(\"Uploaded to cloud storage successfully\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_names\" : [],\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "    train(**input_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f05db4-60fc-4afc-a936-387cded2f4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.12 (Local)",
   "language": "python",
   "name": "tf2-2-12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
