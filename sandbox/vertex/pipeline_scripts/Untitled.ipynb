{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105621ea-cb7a-4f56-9c55-391947783d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 19:29:19.175174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 19:29:26.380797: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-07 19:29:40.923175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-03-07 19:29:40.923549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-03-07 19:29:40.923571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# imports================\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "# from pipeline_scripts.model_file import get_model\n",
    "import json\n",
    "from datetime import datetime\n",
    "# Necessary Functions------------------------------------------\n",
    "\n",
    "\n",
    "# enable XLA (Optimizes the GPU utilization)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"image_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "    \"label\": tf.io.VarLenFeature(tf.float32),\n",
    "    \"label_shape\": tf.io.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "# def load_config(file_path):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         config = json.load(f)\n",
    "#     return config\n",
    "\n",
    "# config = load_config('./pipeline_scripts/config.json')\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "\n",
    "def create_dataset(input_directory):\n",
    "    tfrecord_files = [\n",
    "        f\"{input_directory}{file}\"\n",
    "        for file in tf.io.gfile.listdir(input_directory)\n",
    "        if file.endswith(\".tfrecord\")\n",
    "    ]\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(parse)\n",
    "    return dataset\n",
    "\n",
    "# def create_dataset(input_directory, image_names=[]):\n",
    "#     if len(image_names)==0:\n",
    "#         tfrecord_files = [\n",
    "#         f\"{input_directory}{file}\"\n",
    "#         for file in tf.io.gfile.listdir(input_directory)\n",
    "#         if file.endswith(\".tfrecord\")\n",
    "#     ]\n",
    "#     else:\n",
    "#         names = [name.split(\".\")[0] for name in image_names]\n",
    "#         tfrecord_files = [\n",
    "#             f\"{input_directory}{file}\"\n",
    "#             for file in tf.io.gfile.listdir(input_directory)\n",
    "#             if file.endswith(\".tfrecord\") and tf.io.gfile.basename(file).rsplit('.', 1)[0] in names\n",
    "#         ]\n",
    "#     dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "#     dataset = dataset.map(parse)\n",
    "#     return dataset\n",
    "\n",
    "\n",
    "# pre-processing functions\n",
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    # Convert the input_tensor to a float32 type\n",
    "    input_tensor = tf.cast(input_tensor, tf.float32)\n",
    "\n",
    "    # Calculate the minimum and maximum values along the channel axis\n",
    "    min_val = tf.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "\n",
    "    # Check for potential numerical instability\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "\n",
    "    # Normalize the tensor band-wise to the range [0, 1]\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "\n",
    "    return normalized_tensor\n",
    "\n",
    "\n",
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    # Get the current dimensions\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Calculate the target dimensions\n",
    "    target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "\n",
    "    # Calculate the amount of padding\n",
    "    pad_height = target_height - height\n",
    "    pad_width = target_width - width\n",
    "\n",
    "    # Pad the image\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "def tile_image(fullimg, CHANNELS, TILE_HT, TILE_WD):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    nrows = tiles.shape[0]\n",
    "    ncols = tiles.shape[1]\n",
    "    tiles = tf.reshape(tiles, [nrows, ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def sampling(label_image, threshold_percentage=99.9):\n",
    "    num_zeros = tf.reduce_sum(\n",
    "        tf.cast(tf.equal(label_image, 0), tf.float32), axis=[2, 3, 4]\n",
    "    )\n",
    "\n",
    "    # Calculate the total number of elements in each patch\n",
    "    total_elements = tf.cast(tf.reduce_prod(tf.shape(label_image)[2:]), tf.float32)\n",
    "\n",
    "    # Calculate the percentage of zeros in each patch\n",
    "    percentage_zeros = (num_zeros / total_elements) * 100.0\n",
    "\n",
    "    boolean_mask = percentage_zeros <= threshold_percentage\n",
    "    # Apply the threshold logic\n",
    "    sampled_tensor = tf.cast(percentage_zeros >= threshold_percentage, tf.int32)\n",
    "    return boolean_mask, sampled_tensor\n",
    "\n",
    "\n",
    "def one_hot_encoding(label_tensor):\n",
    "    # Assuming your pixel values are float labels\n",
    "    float_labels = tf.squeeze(\n",
    "        label_tensor, axis=-1\n",
    "    )  # Assuming channel dimension is the last one\n",
    "\n",
    "    # Determine the number of classes dynamically\n",
    "    num_classes = tf.cast(tf.reduce_max(float_labels) + 1, tf.int32)\n",
    "\n",
    "    # One-hot encode each image\n",
    "    one_hot_encoded_images = tf.one_hot(\n",
    "        tf.dtypes.cast(float_labels, tf.int32), depth=num_classes\n",
    "    )\n",
    "\n",
    "    # Print the shape of the resulting tensor and the number of classes\n",
    "    # print(\"Shape of one-hot encoded images:\", one_hot_encoded_images.shape)\n",
    "    # print(\"Number of classes:\", num_classes)\n",
    "\n",
    "    return one_hot_encoded_images\n",
    "\n",
    "\n",
    "# def parsing(\n",
    "#     dataset,\n",
    "#     patch_height,\n",
    "#     patch_width,\n",
    "#     threshold_percentage,\n",
    "#     image_channels,\n",
    "#     label_channels,\n",
    "# ):\n",
    "#     image_patch_tensors_list = []\n",
    "#     label_patch_tensors_list = []\n",
    "\n",
    "#     for parsed_example in dataset:\n",
    "#         image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "#         image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "#         label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "#         label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "\n",
    "#         # image normalization\n",
    "#         image = bandwise_normalize(image)\n",
    "\n",
    "#         # image and label patching\n",
    "#         image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "#         label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "#         # sampling\n",
    "#         sampled_mask, sampled_tensor = sampling(label_patches, threshold_percentage)\n",
    "#         sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "#         sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "#         # one-hot encoding\n",
    "#         sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "#         # save them in the list\n",
    "#         image_patch_tensors_list.append(sampled_image_patches)\n",
    "#         label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "#     return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def parse_example(parsed_example, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "    image_shape = tf.sparse.to_dense(parsed_example[\"image_shape\"])\n",
    "    image = tf.reshape(tf.sparse.to_dense(parsed_example[\"image\"]), image_shape)\n",
    "    label_shape = tf.sparse.to_dense(parsed_example[\"label_shape\"])\n",
    "    label = tf.reshape(tf.sparse.to_dense(parsed_example[\"label\"]), label_shape)\n",
    "\n",
    "    # image normalization\n",
    "    image = bandwise_normalize(image)\n",
    "\n",
    "    # image and label patching\n",
    "    image_patches = tile_image(image, image_channels, patch_height, patch_width)\n",
    "    label_patches = tile_image(label, label_channels, patch_height, patch_width)\n",
    "\n",
    "    # sampling\n",
    "    sampled_mask, _ = sampling(label_patches, threshold_percentage)\n",
    "    sampled_image_patches = tf.boolean_mask(image_patches, sampled_mask)\n",
    "    sampled_label_patches = tf.boolean_mask(label_patches, sampled_mask)\n",
    "\n",
    "    # one-hot encoding\n",
    "    sampled_label_patches = one_hot_encoding(sampled_label_patches)\n",
    "\n",
    "    return sampled_image_patches, sampled_label_patches\n",
    "\n",
    "def parsing_optimized(dataset, patch_height, patch_width, threshold_percentage, image_channels, label_channels):\n",
    "    image_patch_tensors_list = []\n",
    "    label_patch_tensors_list = []\n",
    "\n",
    "    for parsed_example in dataset:\n",
    "        sampled_image_patches, sampled_label_patches = parse_example(parsed_example, patch_height, patch_width, threshold_percentage, image_channels, label_channels)\n",
    "        image_patch_tensors_list.append(sampled_image_patches)\n",
    "        label_patch_tensors_list.append(sampled_label_patches)\n",
    "\n",
    "    return image_patch_tensors_list, label_patch_tensors_list\n",
    "\n",
    "\n",
    "\n",
    "def train_test_datasets(\n",
    "    input_directory,\n",
    "    patch_height,\n",
    "    patch_width,\n",
    "    image_channels,\n",
    "    label_channels,\n",
    "    threshold_percentage,\n",
    "    batch_size,\n",
    "    \n",
    "):\n",
    "    dataset = create_dataset(input_directory)\n",
    "    image_patch_tensors_list, label_patch_tensors_list = parsing(\n",
    "        dataset=dataset,\n",
    "        patch_height=patch_height,\n",
    "        patch_width=patch_width,\n",
    "        image_channels=image_channels,\n",
    "        label_channels=label_channels,\n",
    "        threshold_percentage=threshold_percentage,\n",
    "    )\n",
    "\n",
    "    # Combine images and labels from different pairs\n",
    "    combined_images = tf.concat(image_patch_tensors_list, axis=0)\n",
    "    combined_labels = tf.concat(label_patch_tensors_list, axis=0)\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    combined_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (combined_images, combined_labels)\n",
    "    )\n",
    "    combined_dataset = combined_dataset.shuffle(buffer_size=combined_images.shape[0])\n",
    "\n",
    "    # Split the combined dataset into training and validation sets\n",
    "    train_size = int(0.8 * combined_images.shape[0])\n",
    "    train_dataset = combined_dataset.take(train_size)\n",
    "    val_dataset = combined_dataset.skip(train_size)\n",
    "\n",
    "    # Batch the data using TensorFlow's Dataset API\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client(project=\"gislogics\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))\n",
    "\n",
    "\n",
    "# Modeling--------------------------------------------------\n",
    "\n",
    "\n",
    "def train(**kwargs):\n",
    "    input_directory = kwargs.get(\"input_directory\")\n",
    "    threshold_percentage = kwargs.get(\"threshold_percentage\")\n",
    "    image_channels = kwargs.get(\"image_channels\")\n",
    "    label_channels = kwargs.get(\"label_channels\")\n",
    "    patch_height = kwargs.get(\"patch_height\")\n",
    "    patch_width = kwargs.get(\"patch_width\")\n",
    "    batch_size = kwargs.get(\"batch_size\")\n",
    "    num_classes = kwargs.get(\"num_classes\")\n",
    "    # model_path = config.get(\"model_path\")\n",
    "    bucket_name = kwargs.get(\"bucket_name\")\n",
    "    img_size = (patch_height, patch_width)\n",
    "    # model_name = config.get(\"model_name\")\n",
    "    # image_names = kwargs.get(\"image_names\")\n",
    "\n",
    "    # get the train and test datasets\n",
    "    train_dataset, val_dataset = train_test_datasets(\n",
    "        input_directory,\n",
    "        patch_height,\n",
    "        patch_width,\n",
    "        image_channels,\n",
    "        label_channels,\n",
    "        threshold_percentage,\n",
    "        batch_size,\n",
    "        # image_names\n",
    "    )\n",
    "    print(\"Train and Valid datasets are created\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec4e4d4-23f6-45d8-b341-e3f3f1e25939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 19:29:56.542570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-03-07 19:29:56.543493: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-07 19:29:56.543550: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a7ee842636f0): /proc/driver/nvidia/version does not exist\n",
      "2024-03-07 19:29:56.737202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'parsing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m input_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://tf_records_bucket/tf_records/Untitled Folder/\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# make sure / is there at the end,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# \"image_names\": [],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# \"model_path\": \"trained_model/\",\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     }  \u001b[38;5;66;03m# makesure there is a slash at the end of the path  # Choose an appropriate batch size\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 309\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m img_size \u001b[38;5;241m=\u001b[39m (patch_height, patch_width)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# model_name = config.get(\"model_name\")\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# image_names = kwargs.get(\"image_names\")\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# get the train and test datasets\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# image_names\u001b[39;49;00m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain and Valid datasets are created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 246\u001b[0m, in \u001b[0;36mtrain_test_datasets\u001b[0;34m(input_directory, patch_height, patch_width, image_channels, label_channels, threshold_percentage, batch_size)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_test_datasets\u001b[39m(\n\u001b[1;32m    236\u001b[0m     input_directory,\n\u001b[1;32m    237\u001b[0m     patch_height,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \n\u001b[1;32m    244\u001b[0m ):\n\u001b[1;32m    245\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(input_directory)\n\u001b[0;32m--> 246\u001b[0m     image_patch_tensors_list, label_patch_tensors_list \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m(\n\u001b[1;32m    247\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    248\u001b[0m         patch_height\u001b[38;5;241m=\u001b[39mpatch_height,\n\u001b[1;32m    249\u001b[0m         patch_width\u001b[38;5;241m=\u001b[39mpatch_width,\n\u001b[1;32m    250\u001b[0m         image_channels\u001b[38;5;241m=\u001b[39mimage_channels,\n\u001b[1;32m    251\u001b[0m         label_channels\u001b[38;5;241m=\u001b[39mlabel_channels,\n\u001b[1;32m    252\u001b[0m         threshold_percentage\u001b[38;5;241m=\u001b[39mthreshold_percentage,\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Combine images and labels from different pairs\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     combined_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat(image_patch_tensors_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parsing' is not defined"
     ]
    }
   ],
   "source": [
    "input_params = {\n",
    "        \"input_directory\": \"gs://tf_records_bucket/tf_records/Untitled Folder/\",  # make sure / is there at the end,\n",
    "        # \"image_names\": [],\n",
    "        \"bucket_name\": \"tf_records_bucket\",\n",
    "        \"threshold_percentage\": 99.9,\n",
    "        \"image_channels\": 8,  # 8 bands images as input\n",
    "        \"label_channels\": 1,\n",
    "        \"patch_height\": 8,\n",
    "        \"patch_width\": 8,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_classes\": 23,\n",
    "        # \"model_path\": \"trained_model/\",\n",
    "    }  # makesure there is a slash at the end of the path  # Choose an appropriate batch size\n",
    "\n",
    "train(**input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a85aa-e882-4dfa-af45-4c51d40bcdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.10 (Local)",
   "language": "python",
   "name": "tf2-2-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
