{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVr6KvusuRUm9oknX/aNHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realtechsupport/cocktail/blob/main/sandbox/testing_prediction_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8x6SWWPIQux",
        "outputId": "7568eeba-72c7-4377-c4b8-66ad76c39527"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiyF9MmFDB1H",
        "outputId": "9277aa86-7d58-4b10-da4b-7fa5ddaa5e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "eq5nltmcDK6h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing the images\n",
        "\n",
        "1.   normalize\n",
        "2.   resize\n",
        "3. patches\n",
        "4. create numpyarray out of patches list\n",
        "\n"
      ],
      "metadata": {
        "id": "floU8PA1DVyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the GeoTIFF file\n",
        "with rasterio.open('/content/gdrive/MyDrive/exp/output.tif') as src:\n",
        "    # Read the TIFF data\n",
        "    tiff_data = src.read()\n",
        "\n",
        "    # Get the shape of the TIFF data\n",
        "    num_bands, height, width = tiff_data.shape\n",
        "\n",
        "    print(\"Original image dimensions:\", num_bands, height, width)\n",
        "\n",
        "    print(np.min(tiff_data), np.max(tiff_data))\n",
        "\n",
        "\n",
        "    normalized_image = np.zeros_like(tiff_data, dtype='float32')\n",
        "\n",
        "    for band, count in enumerate(range(tiff_data.shape[0])):\n",
        "        band_data = tiff_data[band, :, :]\n",
        "        band_min = np.min(band_data)\n",
        "        band_max = np.max(band_data)\n",
        "        print(\"band-\", count+1,\"maximum-\",band_max,\"minimum-\",band_min)\n",
        "        #print(band_data)\n",
        "        normalized_band = (band_data - band_min) / (band_max - band_min + 1e-10)\n",
        "        normalized_image[band, :, :] = normalized_band\n",
        "\n",
        "\n",
        "    # Calculate the new width and height that are multiples of the patch size\n",
        "    patch_size = 256  # Replace with your desired patch size\n",
        "    new_width = int(np.floor(width / patch_size)) * patch_size\n",
        "    new_height = int(np.floor(height / patch_size)) * patch_size\n",
        "\n",
        "    print(\"cropped dimensions:\", new_height, new_width)\n",
        "\n",
        "    input_image = np.moveaxis(normalized_image, 0, -1)\n",
        "\n",
        "    # Crop the input_image to the new dimensions\n",
        "    cropped_array = input_image[:new_height, :new_width, :]\n",
        "\n",
        "print(\"Cropped array shape:\", cropped_array.shape)\n",
        "print(np.min(cropped_array), np.max(cropped_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1KIyngBDTC2",
        "outputId": "0659c556-0dd0-413c-84f4-d31b1ef8ef5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4096 4864\n",
            "1.0 10610.0\n",
            "band- 1 maximum- 3905.5 minimum- 1.0\n",
            "band- 2 maximum- 5630.5 minimum- 14.0\n",
            "band- 3 maximum- 6175.5 minimum- 11.0\n",
            "band- 4 maximum- 6969.5 minimum- 1.0\n",
            "band- 5 maximum- 7382.0 minimum- 27.0\n",
            "band- 6 maximum- 10610.0 minimum- 1.0\n",
            "band- 7 maximum- 8313.5 minimum- 1.0\n",
            "band- 8 maximum- 7437.0 minimum- 42.0\n",
            "cropped dimensions: 4096 4864\n",
            "Cropped array shape: (4096, 4864, 8)\n",
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patches = []\n",
        "for i in range(0, cropped_array.shape[0], patch_size):\n",
        "    for j in range(0, cropped_array.shape[1], patch_size):\n",
        "        patch = cropped_array[i:i+patch_size, j:j+patch_size]\n",
        "        patches.append(patch)"
      ],
      "metadata": {
        "id": "SA8FXcMyDsrf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = np.array(patches)"
      ],
      "metadata": {
        "id": "BdIcU3gEEMuQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing the masks:\n",
        "\n",
        "1. resize, squeeze out extra dimension\n",
        "2. create patches\n",
        "3. one-hot encoding\n"
      ],
      "metadata": {
        "id": "hjyQZVqQETVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "with rasterio.open('/content/gdrive/MyDrive/exp/crop_mask.tif') as src:\n",
        "    # Read the TIFF data\n",
        "    output_mask = src.read()\n",
        "\n",
        "    # Calculate the new width and height that are multiples of the patch size\n",
        "    patch_size = 256  # Replace with your desired patch size\n",
        "    new_width = int(np.floor(width / patch_size)) * patch_size\n",
        "    new_height = int(np.floor(height / patch_size)) * patch_size\n",
        "\n",
        "    print(\"cropped dimensions:\", new_height, new_width)\n",
        "\n",
        "    output_mask = np.moveaxis(output_mask, 0, -1)\n",
        "\n",
        "    # Crop the input_image to the new dimensions\n",
        "    cropped_mask = output_mask[:new_height, :new_width, :]\n",
        "\n",
        "print(\"Cropped array shape:\", cropped_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWjwBJsoEyay",
        "outputId": "b9cb4e3f-66a7-46c8-ac0a-153ac0bdc92d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped dimensions: 4096 4864\n",
            "Cropped array shape: (4096, 4864, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_mask = np.squeeze(cropped_mask)"
      ],
      "metadata": {
        "id": "Qy26R7KZE4dR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = []\n",
        "for i in range(0, new_mask.shape[0], patch_size):\n",
        "    for j in range(0, new_mask.shape[1], patch_size):\n",
        "        patch = new_mask[i:i+patch_size, j:j+patch_size]\n",
        "        masks.append(patch)"
      ],
      "metadata": {
        "id": "TCd3tsLTFHWI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "def onehotencoding(labels, num_classes=23):\n",
        "    return to_categorical(labels, num_classes)"
      ],
      "metadata": {
        "id": "nG8ViYs8FEi9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_array = np.array(masks)"
      ],
      "metadata": {
        "id": "fUxb_e_YFU_E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling:"
      ],
      "metadata": {
        "id": "ghyHYcocFbnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "useful_images = []\n",
        "useful_masks = []\n",
        "useless = 0\n",
        "indexes = []\n",
        "for img in range(len(training_images)):\n",
        "    img_name=training_images[img]\n",
        "    mask_name = mask_array[img]\n",
        "\n",
        "    val, counts = np.unique(mask_name, return_counts=True)\n",
        "\n",
        "    if (1 - (counts[0]/counts.sum())) > 0.05:\n",
        "      useful_images.append(img_name)\n",
        "      useful_masks.append(mask_name)\n",
        "      indexes.append(img)\n",
        "      print(\"I am useful\")\n",
        "\n",
        "    else:\n",
        "      print(\"I am useless\")\n",
        "      useless +=1\n",
        "\n",
        "print(\"Total useful images are: \", len(training_images)-useless)\n",
        "print(\"Total useless images are: \", useless)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8-idhJ_RFhWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6746833-e374-4417-f7eb-d878209cf7e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useful\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "I am useless\n",
            "Total useful images are:  36\n",
            "Total useless images are:  268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "useful_training_images = np.array(useful_images)\n",
        "useful_training_masks_array = np.array(useful_masks)"
      ],
      "metadata": {
        "id": "5ldvurrpFvYo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "useful_training_masks = onehotencoding(useful_training_masks_array)"
      ],
      "metadata": {
        "id": "0RgK8R1FKQmq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training:\n",
        "\n",
        "1. model\n",
        "2. training"
      ],
      "metadata": {
        "id": "Q8PQZJURGF6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (256, 256)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (8,))\n",
        "    x = inputs\n",
        "\n",
        "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(\n",
        "        256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(\n",
        "        128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(\n",
        "        64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\",\n",
        "     padding=\"same\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = get_model(img_size=img_size, num_classes=23)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tck_Xdk_TAC",
        "outputId": "6054dd39-ee74-4e78-86b0-99d7ec4368b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 256, 256, 8)]     0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 128, 128, 64)      4672      \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2D  (None, 32, 32, 256)       590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2D  (None, 64, 64, 256)       590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2D  (None, 64, 64, 128)       295040    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_9 (Conv2D  (None, 128, 128, 128)     147584    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_10 (Conv2  (None, 128, 128, 64)      73792     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2  (None, 256, 256, 64)      36928     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 256, 256, 23)      13271     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2895063 (11.04 MB)\n",
            "Trainable params: 2895063 (11.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (8,))\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    conv1 = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
        "    conv2 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(pool2)\n",
        "    conv3 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
        "    concat4 = layers.Concatenate()([up4, conv2])\n",
        "    conv4 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(concat4)\n",
        "    conv4 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv4)\n",
        "\n",
        "    up5 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
        "    concat5 = layers.Concatenate()([up5, conv1])\n",
        "    conv5 = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(concat5)\n",
        "    conv5 = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(conv5)\n",
        "\n",
        "    # Output\n",
        "    outputs = layers.Conv2D(num_classes, 1, activation=\"softmax\")(conv5)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "img_size = (256, 256)\n",
        "num_classes = 23\n",
        "model = get_model(img_size=img_size, num_classes=num_classes)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShEKN_VbBPtE",
        "outputId": "11a49e84-4543-489a-9596-7a00580a7149"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 8)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 16)         1168      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 16)         2320      ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 128, 128, 64)         0         ['conv2d_5[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128, 128, 96)         0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 32)         27680     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 256, 256, 32)         0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256, 256, 48)         0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 16)         6928      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 256, 256, 16)         2320      ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 256, 256, 23)         391       ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 119367 (466.28 KB)\n",
            "Trainable params: 119367 (466.28 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "# 5g\n",
        "# def jacard_coef(y_true, y_pred):\n",
        "#     y_true_f = K.flatten(y_true)\n",
        "#     y_pred_f = K.flatten(y_pred)\n",
        "#     intersection = K.sum(y_true_f * y_pred_f)\n",
        "#     return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "# 5g\n",
        "def multi_unet_model(n_classes=23, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=8): #Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.2)(c1)  # Original 0.1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.2)(c2)  # Original 0.1\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.2)(c8)  # Original 0.1\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.2)(c9)  # Original 0.1\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qCSqpK4yGKcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = multi_unet_model(n_classes=23, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=8)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S6jKtoxAWu9",
        "outputId": "6952bb39-d58e-4541-d7fd-83dbf7a15f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 256, 256, 8)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 256, 256, 16)         1168      ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256, 256, 16)         0         ['conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 256, 256, 16)         2320      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d_16[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 128, 128, 32)         4640      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128, 128, 32)         0         ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 128, 128, 32)         9248      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_18[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 64, 64, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64, 64, 64)           0         ['conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 64)           36928     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_20[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32, 32, 128)          0         ['conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 32, 32, 128)          147584    ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_22[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 16, 16, 256)          0         ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 16, 16, 256)          590080    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_12 (Conv2  (None, 32, 32, 128)          131200    ['conv2d_24[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 256)          0         ['conv2d_transpose_12[0][0]', \n",
            "                                                                     'conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 32, 32, 128)          0         ['conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 32, 32, 128)          147584    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_13 (Conv2  (None, 64, 64, 64)           32832     ['conv2d_26[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_13[0][0]', \n",
            " )                                                                   'conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 64, 64, 64)           0         ['conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 64, 64, 64)           36928     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_14 (Conv2  (None, 128, 128, 32)         8224      ['conv2d_28[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_14[0][0]', \n",
            " )                                                                   'conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 128, 128, 32)         0         ['conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 128, 128, 32)         9248      ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_15 (Conv2  (None, 256, 256, 16)         2064      ['conv2d_30[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_15[0][0]', \n",
            " )                                                                   'conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 256, 256, 16)         0         ['conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 256, 256, 16)         2320      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 256, 256, 23)         391       ['conv2d_32[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1942199 (7.41 MB)\n",
            "Trainable params: 1942199 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(useful_training_images,\n",
        "                                                    useful_training_masks, test_size = 0.20, random_state = 42)\n",
        "\n",
        "\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "\n",
        "\n",
        "metrics=['accuracy']\n",
        "\n",
        "\n",
        "#model = multi_unet_model(n_classes=23, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history1 = model.fit(X_train, y_train,\n",
        "                    batch_size = 16,\n",
        "                    verbose=1,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    shuffle=False)\n",
        "\n",
        "model.save('/content/gdrive/MyDrive/exp/smallmodel_3.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4xRz7hSGNVT",
        "outputId": "b5d92f85-9208-417b-87a9-41b7b8201ade"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 8)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 16)         1168      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 16)         2320      ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 128, 128, 64)         0         ['conv2d_5[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128, 128, 96)         0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 32)         27680     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 32)         9248      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 256, 256, 32)         0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256, 256, 48)         0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 16)         6928      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 256, 256, 16)         2320      ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 256, 256, 23)         391       ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 119367 (466.28 KB)\n",
            "Trainable params: 119367 (466.28 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 22s 10s/step - loss: 3.1380 - accuracy: 0.0069 - val_loss: 3.1122 - val_accuracy: 0.0792\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 21s 13s/step - loss: 3.1039 - accuracy: 0.1176 - val_loss: 3.0641 - val_accuracy: 0.1202\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 18s 7s/step - loss: 3.0393 - accuracy: 0.1836 - val_loss: 2.9096 - val_accuracy: 0.8577\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 19s 9s/step - loss: 2.8250 - accuracy: 0.8120 - val_loss: 2.4037 - val_accuracy: 0.8659\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 18s 9s/step - loss: 2.1910 - accuracy: 0.8197 - val_loss: 1.3127 - val_accuracy: 0.8721\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 1.2926 - accuracy: 0.8243 - val_loss: 1.1090 - val_accuracy: 0.8758\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 18s 8s/step - loss: 1.5985 - accuracy: 0.8277 - val_loss: 1.1086 - val_accuracy: 0.8759\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 1.4665 - accuracy: 0.8277 - val_loss: 0.8986 - val_accuracy: 0.8759\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 19s 8s/step - loss: 1.1729 - accuracy: 0.8277 - val_loss: 1.0708 - val_accuracy: 0.8759\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 19s 10s/step - loss: 1.2457 - accuracy: 0.8277 - val_loss: 1.1652 - val_accuracy: 0.8759\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 1.2464 - accuracy: 0.8277 - val_loss: 0.9678 - val_accuracy: 0.8759\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 1.1086 - accuracy: 0.8277 - val_loss: 0.8385 - val_accuracy: 0.8759\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 1.1228 - accuracy: 0.8277 - val_loss: 0.8454 - val_accuracy: 0.8759\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 1.1455 - accuracy: 0.8277 - val_loss: 0.8186 - val_accuracy: 0.8759\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 19s 9s/step - loss: 1.0728 - accuracy: 0.8277 - val_loss: 0.8516 - val_accuracy: 0.8759\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 18s 9s/step - loss: 1.0519 - accuracy: 0.8277 - val_loss: 0.8894 - val_accuracy: 0.8759\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 1.0436 - accuracy: 0.8277 - val_loss: 0.8308 - val_accuracy: 0.8759\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 0.9971 - accuracy: 0.8277 - val_loss: 0.7716 - val_accuracy: 0.8759\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 0.9946 - accuracy: 0.8277 - val_loss: 0.7607 - val_accuracy: 0.8759\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 0.9702 - accuracy: 0.8277 - val_loss: 0.7700 - val_accuracy: 0.8759\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 19s 9s/step - loss: 0.9459 - accuracy: 0.8277 - val_loss: 0.7787 - val_accuracy: 0.8759\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 18s 9s/step - loss: 0.9286 - accuracy: 0.8277 - val_loss: 0.7365 - val_accuracy: 0.8758\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 0.9035 - accuracy: 0.8277 - val_loss: 0.7125 - val_accuracy: 0.8758\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 17s 8s/step - loss: 0.8881 - accuracy: 0.8277 - val_loss: 0.7079 - val_accuracy: 0.8758\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 0.8619 - accuracy: 0.8277 - val_loss: 0.7070 - val_accuracy: 0.8758\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 0.8408 - accuracy: 0.8277 - val_loss: 0.6723 - val_accuracy: 0.8758\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 20s 9s/step - loss: 0.8197 - accuracy: 0.8277 - val_loss: 0.6622 - val_accuracy: 0.8758\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 0.7955 - accuracy: 0.8277 - val_loss: 0.6639 - val_accuracy: 0.8758\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 17s 9s/step - loss: 0.7788 - accuracy: 0.8277 - val_loss: 0.6483 - val_accuracy: 0.8758\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 17s 7s/step - loss: 0.7669 - accuracy: 0.8277 - val_loss: 0.6607 - val_accuracy: 0.8758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model prediction\n",
        "\n",
        "1. load the model\n",
        "2. preprocess the image - normalization, resizing, patching\n",
        "3. predict using the model\n",
        "4. post process the patches - weighted argmax\n",
        "5. stictch\n",
        "6. display"
      ],
      "metadata": {
        "id": "CLmpYSnPGbQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/gdrive/MyDrive/exp/smallmodel_3.hdf5', compile=False)"
      ],
      "metadata": {
        "id": "6f9z9HmzGc-4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GeoTIFF file\n",
        "with rasterio.open('/content/gdrive/MyDrive/exp/output.tif') as src:\n",
        "    # Read the TIFF data\n",
        "    tiff_data = src.read()\n",
        "\n",
        "    # Get the shape of the TIFF data\n",
        "    num_bands, height, width = tiff_data.shape\n",
        "\n",
        "    print(\"Original image dimensions:\", num_bands, height, width)\n",
        "\n",
        "    print(np.min(tiff_data), np.max(tiff_data))\n",
        "\n",
        "\n",
        "    normalized_image = np.zeros_like(tiff_data, dtype='float32')\n",
        "\n",
        "    for band, count in enumerate(range(tiff_data.shape[0])):\n",
        "        band_data = tiff_data[band, :, :]\n",
        "        band_min = np.min(band_data)\n",
        "        band_max = np.max(band_data)\n",
        "        print(\"band-\", count+1,\"maximum-\",band_max,\"minimum-\",band_min)\n",
        "        #print(band_data)\n",
        "        normalized_band = (band_data - band_min) / (band_max - band_min + 1e-10)\n",
        "        normalized_image[band, :, :] = normalized_band\n",
        "\n",
        "    # Calculate the new width and height that are multiples of the patch size\n",
        "    patch_size = 256  # Replace with your desired patch size\n",
        "    new_width = int(np.floor(width / patch_size)) * patch_size\n",
        "    new_height = int(np.floor(height / patch_size)) * patch_size\n",
        "\n",
        "    print(\"cropped dimensions:\", new_height, new_width)\n",
        "\n",
        "    input_image = np.moveaxis(normalized_image, 0, -1)\n",
        "\n",
        "    # Crop the input_image to the new dimensions\n",
        "    cropped_array = input_image[:new_height, :new_width, :]\n",
        "\n",
        "print(\"Cropped array shape:\", cropped_array.shape)\n",
        "print(np.min(cropped_array), np.max(cropped_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0pq8tPCG9fG",
        "outputId": "b7112af4-dfd5-4438-fe94-e4c1c6849caf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image dimensions: 8 4096 4864\n",
            "1.0 10610.0\n",
            "band- 1 maximum- 3905.5 minimum- 1.0\n",
            "band- 2 maximum- 5630.5 minimum- 14.0\n",
            "band- 3 maximum- 6175.5 minimum- 11.0\n",
            "band- 4 maximum- 6969.5 minimum- 1.0\n",
            "band- 5 maximum- 7382.0 minimum- 27.0\n",
            "band- 6 maximum- 10610.0 minimum- 1.0\n",
            "band- 7 maximum- 8313.5 minimum- 1.0\n",
            "band- 8 maximum- 7437.0 minimum- 42.0\n",
            "cropped dimensions: 4096 4864\n",
            "Cropped array shape: (4096, 4864, 8)\n",
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 256"
      ],
      "metadata": {
        "id": "0qo-YOTtHF8z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches = []\n",
        "for i in range(0, cropped_array.shape[0], patch_size):\n",
        "    for j in range(0, cropped_array.shape[1], patch_size):\n",
        "        patch = cropped_array[i:i+patch_size, j:j+patch_size]\n",
        "        patches.append(patch)"
      ],
      "metadata": {
        "id": "1oOS2wCSHJrU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 23  # Total number of classes including class 0\n",
        "\n",
        "# Define the class weights (0 for class 0, equal weight for other classes)\n",
        "class_weights = np.ones(num_classes)\n",
        "class_weights[0] = 0  # Set weight 0 for class 0\n",
        "class_weights /= np.sum(class_weights)  # Normalize to ensure sum equals 1\n",
        "\n"
      ],
      "metadata": {
        "id": "_1A7wpXqHUpI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuIK7vnUNUDG",
        "outputId": "c11f2051-9b5a-4fc7-900d-edba0f3c83ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
              "       0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
              "       0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
              "       0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
              "       0.04545455, 0.04545455, 0.04545455])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_segmentation(patches):\n",
        "    # Make predictions using the loaded model\n",
        "\n",
        "    seg_patches = []\n",
        "    for patch in patches:\n",
        "        image = tf.expand_dims(patch, axis=0)\n",
        "        prediction = model.predict(image)\n",
        "        weighted_prediction = np.argmax(prediction * class_weights, axis=-1)\n",
        "        seg_patches.append(weighted_prediction)\n",
        "\n",
        "    return seg_patches"
      ],
      "metadata": {
        "id": "Omi_c4d2HNeS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_patches = predict_segmentation(patches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GOGziITHtiZ",
        "outputId": "f686131b-81bb-44b1-f311-c679ab2c6c1d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 332ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 225ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 0s 225ms/step\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 219ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(np.array(predicted_patches),return_counts = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8GKckGROKsw",
        "outputId": "cead84b1-48c9-4651-9422-53efe0944110"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1,  3,  4, 10, 11, 22]),\n",
              " array([19341618,      304,    76608,   153827,   196763,   153824]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "stitched_array = np.zeros((3840,4608), dtype=cropped_array.dtype)"
      ],
      "metadata": {
        "id": "h9DegNY7H0PS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stitched_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QvRlp2tOp3j",
        "outputId": "230b49a4-7931-418d-d518-1db68efbf30a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3840, 4608)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_idx = 0\n",
        "for i in range(0, 3840, 256):\n",
        "    for j in range(0, 4608, 256):\n",
        "        patch = predicted_patches[patch_idx]\n",
        "        stitched_array[i:i+256, j:j+256] = patch\n",
        "        patch_idx += 1"
      ],
      "metadata": {
        "id": "KvdvGVbeH3wT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(stitched_array, return_counts= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbXM2BxnNEO2",
        "outputId": "b130fe4e-03ca-4508-f72f-7b8b1eba40f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  3.,  4., 10., 11., 22.], dtype=float32),\n",
              " array([17177484,      270,    68040,   136622,   175684,   136620]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Create an array with class labels (example segmentation mask)\n",
        "segmentation_mask = stitched_array  # Example labels\n",
        "\n",
        "# Define the class-color mapping\n",
        "class_colors = {\n",
        "    1: ( 5, 5, 230),\n",
        "    2: (190, 60, 15),\n",
        "    3: (65, 240, 125),\n",
        "    4: (105, 200, 95),\n",
        "    5: ( 30, 115, 10),\n",
        "    6: ( 255, 196, 34),\n",
        "    7: (110, 85, 5),\n",
        "    8: ( 235, 235, 220),\n",
        "    9: (120, 216, 47),\n",
        "    10: ( 84, 142, 128),\n",
        "    11: ( 84, 142, 128),\n",
        "    12: ( 84, 142, 128),\n",
        "    13: ( 50, 255, 215),\n",
        "    14: ( 50, 255, 215),\n",
        "    15: ( 50, 255, 215),\n",
        "    16: ( 193, 255, 0),\n",
        "    17: ( 105, 200, 95),\n",
        "    18: (105, 200, 95),\n",
        "    19: ( 105, 200, 95),\n",
        "    20: (193, 255, 0),\n",
        "    21: ( 255, 50, 185),\n",
        "    22: (255, 255, 255),\n",
        "}\n",
        "\n",
        "# Create a colormap using the class-color mapping\n",
        "colors = [class_colors[i] for i in range(1, 23)]\n",
        "cmap = ListedColormap(colors)\n",
        "\n",
        "# Create a figure and axis for the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Plot the segmentation mask using the custom colormap\n",
        "image = ax.imshow(segmentation_mask, cmap=cmap, vmin=1, vmax=22)\n",
        "\n",
        "# Add a colorbar to show the class-color mapping\n",
        "cbar = plt.colorbar(image, ax=ax, ticks=list(class_colors.keys()))\n",
        "cbar.set_label('Classes')\n",
        "\n",
        "# Show the plot\n",
        "plt.title('Segmentation Mask')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "aSfZDT9hQXvo",
        "outputId": "58b8fa0c-f2b8-4681-a7aa-e0993322d519"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}